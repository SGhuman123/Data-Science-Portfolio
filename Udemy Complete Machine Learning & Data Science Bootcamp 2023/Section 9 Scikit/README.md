# Scikit-Learn Section

In the file titled **`Section9.ipynb`**, this was dedicated to exploring how the Scikit Learn library worked. I explored the following:

-	An end-to-end Scikit-Learn workflow
-	Getting the data ready: Through splitting the data into training, testing and validation data. Then conducting data imputation and feature encoding.
-	Choosing the right machine learning estimator/algorithm/model for your problem: Learning how to use the Scikit-Learn algorithm cheat sheet for regression, classification, clustering and dimensionality reduction problems.
-	Fitting your chosen machine learning model to data and using it to make a prediction.
-	Evaluating a machine learning model: Through methods such as `.score()` and cross-validation (`cross_val_score`). Alongside other metrics such as accuracy, area under ROC curve, confusion matrix and the classification report.
    -	More specifically for this notebook I touched on regression-related problems and had to look at regression model evaluation metrics such as **R^2**, **Mean Absolute Error (MAE)**, **Mean Squared Error (MSE)**
-	Improving predictions through experimentation (hyperparameter tuning) through methods such as RandomSearchCV and GridSearchCV
-	Saving and loading a pre-trained model
-	Putting it all together in a pipeline


In the file titled **`scikit-learn-exercises.ipynb`**, I did the practice exercises as part of the course. 

In the file titled **`scikit-learn -exercises-solutions.ipynb`**, this was the solution as part of the course given by the course instructor.
