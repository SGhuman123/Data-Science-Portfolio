{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNoWuc7dbbMMqExGG9sZ1x4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SGhuman123/Data-Science-Portfolio/blob/main/Udemy%20TensorFlow%20Developer%20Certificate%20Bootcamp/Section%208%20Introduction%20to%20NLP/08_introduction_to_nlp_in_tensorflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08. Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-example-nlp-problems.png)\n",
        "*A handful of example natural language processing (NLP) and natural language understanding (NLU) problems. These are also often referred to as sequence problems (going from one sequence to another).*\n",
        "\n",
        "[Natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq).\n",
        "\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "Under the umbrellas of text and speech there are many different things you might want to do.\n",
        "\n",
        "If you're building an email application, you might want to scan incoming emails to see if they're spam or not spam (classification).\n",
        "\n",
        "If you're trying to analyse customer feedback complaints, you might want to discover which section of your business they're for.\n",
        "\n",
        "> üîë **Note:** Both of these types of data are often referred to as *sequences* (a sentence is a sequence of words). So a common term you'll come across in NLP problems is called *seq2seq*, in other words, finding information in one sequence to produce another sequence (e.g. converting a speech command to a sequence of text-based steps).\n",
        "\n",
        "To get hands-on with NLP in TensorFlow, we're going to practice the steps we've used previously but this time with text data:\n",
        "\n",
        "```\n",
        "Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n",
        "```\n",
        "\n",
        "> üìñ **Resource:** For a great overview of NLP and the different problems within it, read the article [*A Simple Introduction to Natural Language Processing*](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32).\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "Let's get specific hey?\n",
        "\n",
        "* Downloading a text dataset\n",
        "* Visualizing text data\n",
        "* Converting text into numbers using tokenization\n",
        "* Turning our tokenized text into an embedding\n",
        "* Modelling a text dataset\n",
        "  * Starting with a baseline (TF-IDF)\n",
        "  * Building several deep learning text models\n",
        "    * Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* Comparing the performance of each our models\n",
        "* Combining our models into an ensemble\n",
        "* Saving and loading a trained model\n",
        "* Find the most wrong predictions\n"
      ],
      "metadata": {
        "id": "fDiezli5w_7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for GPU\n",
        "\n",
        "In order for our deep learning models to run as fast as possible, we'll need access to a GPU.\n",
        "\n",
        "In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
        "\n",
        "After selecting GPU, you may have to restart the runtime."
      ],
      "metadata": {
        "id": "sENj_PsmxelO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya6AamIYxkuW",
        "outputId": "a2202dc4-7fb5-4fe3-a1c4-2f8b9ed3a925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ccd10d39-041a-84d3-d0ab-bfa3c768e660)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions\n",
        "\n",
        "In past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n",
        "\n",
        "Rather than rewrite all of these, we can import a script and load them in from there.\n",
        "\n",
        "The script containing our helper functions can be [found on GitHub](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py)."
      ],
      "metadata": {
        "id": "Rzq3XsMVxlKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMzpz1WTxlQU",
        "outputId": "7aef4ad3-fe40-4030-88b6-a1952418e796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-02 16:07:21--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-02 16:07:21 (84.2 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functios for the notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys, unzip_data"
      ],
      "metadata": {
        "id": "oMRrZB6PxlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as [disaster or not disaster](https://www.kaggle.com/c/nlp-getting-started/data)). This contains text-based Tweets about natural disasters.\n",
        "\n",
        "The Real Tweets are actually about disasters, for example:\n",
        "\n",
        "```\n",
        "Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n",
        "```\n",
        "\n",
        "The Not Real Tweets are Tweets not about disasters (they can be on anything), for example:\n",
        "\n",
        "```\n",
        "'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n",
        "```\n",
        "\n",
        "See the original source here: https://www.kaggle.com/competitions/nlp-getting-started\n",
        "\n",
        "> üîë **Note:** The original downloaded data has not been altered to how you would download it from Kaggle."
      ],
      "metadata": {
        "id": "UbVlpPWfxlc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip the data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnw-DmwPxlkC",
        "outputId": "7b1787fe-91b7-4611-9818-b972cc4395e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-02 16:07:27--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.207, 74.125.20.207, 108.177.98.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-02 16:07:27 (99.8 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ],
      "metadata": {
        "id": "VRqHkuiaUAay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "Right now, our text data samples are in the form of `.csv` files. For an easy way to make them visual, let's turn them into pandas DataFrame's.\n",
        "___\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas...\n",
        "\n",
        "> üìñ **Reading:** You might come across text datasets in many different formats. Aside from CSV files (what we're working with), you'll probably encounter `.txt` files and `.json` files too. For working with these type of files, I'd recommend reading the two following articles by RealPython:\n",
        "* [How to Read and Write Files in Python](https://realpython.com/read-write-files-python/)\n",
        "* [Working with JSON Data in Python](https://realpython.com/python-json/)"
      ],
      "metadata": {
        "id": "sMDmApTmxlrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Adb0devSxlyq",
        "outputId": "8ed0a95e-bc26-4711-cd83-1b4af86f8f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54430fe9-6114-4fb9-9c9f-5decee8c27c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54430fe9-6114-4fb9-9c9f-5decee8c27c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54430fe9-6114-4fb9-9c9f-5decee8c27c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54430fe9-6114-4fb9-9c9f-5decee8c27c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4b1d97e-288e-4998-ba68-d38a50e92913\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4b1d97e-288e-4998-ba68-d38a50e92913')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4b1d97e-288e-4998-ba68-d38a50e92913 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EovGapeJxl6F",
        "outputId": "9c94971e-75be-4f84-e3b7-a28c4b57886e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training data we downloaded is probably shuffled already. But just to be sure, let's shuffle it again."
      ],
      "metadata": {
        "id": "W9EPDPO8Ulvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "NEVSPvU4xmB9",
        "outputId": "3bf66c85-eb5c-4b08-b7e3-59fe6e0832ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5809814e-5441-44c0-b1f0-ce02b87bd7ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5809814e-5441-44c0-b1f0-ce02b87bd7ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5809814e-5441-44c0-b1f0-ce02b87bd7ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5809814e-5441-44c0-b1f0-ce02b87bd7ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddfb8c91-3970-4978-84d9-a0602389bda3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddfb8c91-3970-4978-84d9-a0602389bda3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddfb8c91-3970-4978-84d9-a0602389bda3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the training data has a `\"target\"` column.\n",
        "\n",
        "We're going to be writing code to find patterns (e.g. different combinations of words) in the `\"text\"` column of the training dataset to predict the value of the `\"target\"` column.\n",
        "\n",
        "The test dataset doesn't have a `\"target\"` column.\n",
        "\n",
        "```\n",
        "Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)\n",
        "```\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-text-classification-inputs-and-outputs.png)\n",
        "*Example text classification inputs and outputs for the problem of classifying whether a Tweet is about a disaster or not.*"
      ],
      "metadata": {
        "id": "joqnNk0ZUssR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the test dataframe look like?\n",
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LlY2v-lexmJ9",
        "outputId": "dfedd530-ba3f-453b-a2b3-b5c902d01709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c86d5a5-be32-449c-907e-13609c7ef0de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c86d5a5-be32-449c-907e-13609c7ef0de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c86d5a5-be32-449c-907e-13609c7ef0de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c86d5a5-be32-449c-907e-13609c7ef0de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c428d2f1-11bf-4a97-8833-762566b143e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c428d2f1-11bf-4a97-8833-762566b143e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c428d2f1-11bf-4a97-8833-762566b143e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check how many examples of each target we have."
      ],
      "metadata": {
        "id": "vVcSWKOlU3eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbePgm-lxmSF",
        "outputId": "6c0b3f4a-0e1a-4fb1-eecb-6244454f8450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have two target values, we're dealing with a **binary classification** problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (`target = 0`) and 40% positive class (`target = 1`).\n",
        "\n",
        "Where,\n",
        "\n",
        "* `1` = a real disaster Tweet\n",
        "* `0` = not a real disaster Tweet\n",
        "\n",
        "And what about the total number of samples we have?"
      ],
      "metadata": {
        "id": "KCNLEhiQVD5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz4xvKMdq50O",
        "outputId": "87c9419a-ce16-476f-f7a2-5cf1d9e141eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, seems like we've got a decent amount of training and test data. If anything, we've got an abundance of testing examples, usually a split of 90/10 (90% training, 10% testing) or 80/20 is suffice.\n",
        "\n",
        "Okay, time to visualize, let's write some code to visualize random text samples.\n",
        "\n",
        "> ü§î **Question:** Why visualize random samples? You could visualize samples in order but this could lead to only seeing a certain subset of data. Better to visualize a substantial quantity (100+) of random samples to get an idea of the different kinds of data you're working with. In machine learning, never underestimate the power of randomness."
      ],
      "metadata": {
        "id": "92V6psgUVJwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lu0n7pEsTEz",
        "outputId": "3c8cc0b2-7ff4-4b11-f821-ef427bd8a51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "European Fitba till Christmas  ARMAGEDDON\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@LisaVanderpump How many dogs do you have and are they all rescue dogs?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "In a dream you saw a way to survive and you were full of joy.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Apollo Brown - 'Detonate' f. M.O.P. | http://t.co/H1xiGcEn7F\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Severe storm weakening as it moves SE towards Lubbock area.  Outflow boundary may create dust and 50 mph gusts http://t.co/pw3tZU0tay\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n",
        "\n",
        "When our model trains (tries patterns in the Tweet samples), it'll only see data from the training set and we can see how it performs on unseen data using the validation set.\n",
        "\n",
        "We'll convert our splits from pandas Series datatypes to lists of strings (for the text) and lists of ints (for the labels) for ease of use later.\n",
        "\n",
        "To split our training dataset and create a validation dataset, we'll use Scikit-Learn's [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method and dedicate 10% of the training samples to the validation set."
      ],
      "metadata": {
        "id": "yA2PG_-fsTK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GGV6aXxBsTRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,  # use 10% of training data for validation split\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "4A-Rltm-sTYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzOodbh5sTff",
        "outputId": "22aebbb6-8ab2-450b-c1ba-7b248e4b3732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxOMj8KsTma",
        "outputId": "38484713-3b98-470c-a39a-070d6de912c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "We've got a training set and a validation set containing Tweets and labels.\n",
        "\n",
        "Our labels are in numerical form (`0` and `1`) but our Tweets are in string form.\n",
        "\n",
        "> ü§î **Question:** What do you think we have to do before we can use a machine learning algorithm with our text data?\n",
        "\n",
        "If you answered something along the lines of \"turn it into numbers\", you're correct. A machine learning algorithm requires its inputs to be in numerical form.\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "  1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being `0`, \"love\" being `1` and \"TensorFlow\" being `2`. In this case, every word in a sequence considered a single **token**.\n",
        "  2. **Character-level tokenization**, such as converting the letters A-Z to values `1-26`. In this case, every character in a sequence considered a single **token**.\n",
        "  3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**.\n",
        "* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "  1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)) and an embedding representation will be learned during model training.\n",
        "  2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tokenization-vs-embedding.png)\n",
        "*Example of **tokenization** (straight mapping from word to number) and **embedding** (richer representation of relationships between tokens).*\n",
        "\n",
        "> ü§î **Question:** What level of tokenzation should I use? What embedding should should I choose?\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [`tf.keras.layers.concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)).\n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](http://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on [TensorFlow Hub](https://tfhub.dev/s?module-type=text-embedding) are great places to start.\n",
        "\n",
        "> üîë **Note:** Much like searching for a pre-trained computer vision model, you can search for pre-trained word embeddings to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ],
      "metadata": {
        "id": "fxtyIafQsTuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "Enough talking about tokenization and embeddings, let's create some.\n",
        "\n",
        "We'll practice tokenzation (mapping our words to numbers) first.\n",
        "\n",
        "To tokenize our words, we'll use the helpful preprocessing layer [`tf.keras.layers.experimental.preprocessing.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization).\n",
        "\n",
        "The `TextVectorization` layer takes the following parameters:\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* `standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n",
        "* `output_mode` -  How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), `\"count\"` or `\"tf-idf\"`. See documentation for more.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to `False`, if `True`, the output feature axis will be padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than `max_tokens`. Only valid in certain modes, see docs for more.\n",
        "\n",
        "Let's see it in action."
      ],
      "metadata": {
        "id": "xn4fRSfasT1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftBC2dbCsT8l",
        "outputId": "cb6b6cd9-0879-425a-d431-c7eb615aa435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVctorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=10000, # How many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "-N6rPkwksUED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences[0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "852Kxq7Y1PMx",
        "outputId": "100b7a29-8c41-4ea0-a532-25a998986c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens` (the number of words in the vocabulary), multiples of 10,000 (`10,000`, `20,000`, `30,000`) or the exact number of unique words in your text (e.g. `32,179`) are common values.\n",
        "\n",
        "For our use case, we'll use `10,000`.\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ],
      "metadata": {
        "id": "sES9pdxWWYvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split(\" \")) for i in train_sentences]) / len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G6OWpIPsULj",
        "outputId": "288e7559-03b0-4f23-d316-2f6f743d082c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create another `TextVectorization` object using our custom parameters."
      ],
      "metadata": {
        "id": "6E9RLoZoWiL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how mant words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "4aq9L8wssUS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful!\n",
        "\n",
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training text."
      ],
      "metadata": {
        "id": "Hhw9TqI0WlUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "MRDbHdSmq565"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_sentences[:10]"
      ],
      "metadata": {
        "id": "Jaj_aqFs2gQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence (one similar to what you might see in the training data)."
      ],
      "metadata": {
        "id": "H7gJH9w-WquP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer(sample_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_vAs8hZq6BK",
        "outputId": "010bf752-c467-4739-aa78-908f5a86c1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
              "array([264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful, it seems we've got a way to turn our text into numbers (in this case, word-level tokenization). Notice the 0's at the end of the returned tensor, this is because we set `output_sequence_length=15`, meaning no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15.\n",
        "\n",
        "How about we try our `text_vectorizer` on a few random sentences?"
      ],
      "metadata": {
        "id": "9_Hd9g9MWtuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nVectorized text:\\n {text_vectorizer(random_sentence)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2O8tTzKq6Ih",
        "outputId": "6a8495b0-96cd-4e49-afa9-3ad493866799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Motorcyclist bicyclist injured in Denver collision on Broadway: At least two people were taken to a local¬â√õ_ http://t.co/2aCRGdqhJ0        \n",
            "\n",
            "Vectorized text:\n",
            " [1499 1715  243    4 1145  584   11 1889   17  506  116   57   67  806\n",
            "    5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good!\n",
        "\n",
        "Finally, we can check the unique tokens in our vocabulary using the `get_vocabulary()` method."
      ],
      "metadata": {
        "id": "WC4lca8qWyXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb6TZ19Vq6P6",
        "outputId": "aa96776c-11ba-4fab-b291-7ed993bec212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_sentences"
      ],
      "metadata": {
        "id": "YJ-1mYeHq6XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. `1` = I, `2` = love, `3` = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n",
        "\n",
        "Knowing these, let's make an embedding layer.\n"
      ],
      "metadata": {
        "id": "I-DfZQtFq6fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length # how long is each input\n",
        "                             )\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kze4Q_yF4Et3",
        "outputId": "ed5bab31-4942-4aac-be76-684888ad4ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x78aab415f700>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent, notice how `embedding` is a TensoFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns.\n",
        "\n",
        "How about we try it out on a sample sentence?"
      ],
      "metadata": {
        "id": "TeLTfR8eXcLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPX_o8Ex4Eze",
        "outputId": "1b9f1ea0-7191-4216-9f4c-157a364d8ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Plot\n",
            "In the futurea totalitarian government employs a force known as Firemen to seek out and destroy all literature https://t.co/DRfKarLz1d\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02084069, -0.0235215 ,  0.04255316, ...,  0.02597657,\n",
              "          0.01621536,  0.0331482 ],\n",
              "        [-0.04878777,  0.04451096,  0.03132245, ..., -0.02965918,\n",
              "         -0.03481448, -0.04505401],\n",
              "        [ 0.02153409, -0.04824049,  0.02666788, ..., -0.00237669,\n",
              "         -0.03009018, -0.00971466],\n",
              "        ...,\n",
              "        [ 0.02151444,  0.01410898,  0.04525946, ..., -0.04872377,\n",
              "         -0.03877106,  0.03832252],\n",
              "        [-0.03731189, -0.02028248,  0.04030311, ...,  0.02300242,\n",
              "         -0.0142025 ,  0.04769966],\n",
              "        [ 0.01162566, -0.03410751,  0.02700515, ...,  0.00870188,\n",
              "         -0.01885352, -0.03150073]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ],
      "metadata": {
        "id": "5teusuVVXgKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU3wqZrR4E5g",
        "outputId": "5d2b255b-2050-447b-83fe-bcda5ce1c595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.02084069, -0.0235215 ,  0.04255316, -0.00266907, -0.00954022,\n",
              "        -0.00544114, -0.00480523,  0.01346257, -0.00492145,  0.01158165,\n",
              "         0.0199695 , -0.01293279, -0.02669169,  0.04980944, -0.02500908,\n",
              "         0.03550149,  0.03100982, -0.00153322,  0.00093848,  0.03280776,\n",
              "        -0.00867103, -0.0035804 ,  0.01728256,  0.00729012, -0.00088159,\n",
              "        -0.01587345, -0.03852886, -0.01349164,  0.01359273,  0.00623559,\n",
              "         0.03343484,  0.00471228,  0.00160328,  0.04520837, -0.01650808,\n",
              "        -0.02111198,  0.03780336, -0.04384325, -0.04428469,  0.02511027,\n",
              "         0.00072188, -0.04342772, -0.04413431,  0.00124264,  0.04541254,\n",
              "        -0.00080813,  0.01731637, -0.02275376, -0.03433467,  0.03111095,\n",
              "        -0.01685778,  0.02423489,  0.02289757,  0.03626937, -0.02917447,\n",
              "        -0.04381092, -0.01246034, -0.03003713,  0.00147014, -0.03056144,\n",
              "        -0.0036675 ,  0.04033543,  0.00880668, -0.04823248,  0.03557468,\n",
              "        -0.04995064, -0.00487942, -0.03378417, -0.02353711, -0.02067297,\n",
              "        -0.01010147, -0.00688851,  0.02819488,  0.04189858,  0.00764601,\n",
              "         0.01926372,  0.01957465,  0.0377388 ,  0.02511302,  0.02617105,\n",
              "        -0.00529052,  0.01323363, -0.04469092, -0.01300551,  0.00133722,\n",
              "        -0.03017211, -0.00049828, -0.00881494,  0.02510407, -0.03136857,\n",
              "         0.02406711,  0.0152871 , -0.02126612, -0.04471798, -0.01860014,\n",
              "         0.00717063,  0.02897668,  0.02809087, -0.04711813,  0.01750323,\n",
              "         0.02162028, -0.0059482 , -0.00277661,  0.03528045,  0.04990852,\n",
              "         0.01482535, -0.0484208 , -0.02370265,  0.00696206, -0.02082187,\n",
              "        -0.00550926,  0.01473531,  0.02954943, -0.01359951,  0.04793351,\n",
              "        -0.0036323 , -0.00900783,  0.01887082,  0.028357  ,  0.01971105,\n",
              "         0.03332099, -0.0341372 , -0.00818139,  0.00913316, -0.03539415,\n",
              "         0.02597657,  0.01621536,  0.0331482 ], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Plot\\nIn the futurea totalitarian government employs a force known as Firemen to seek out and destroy all literature https://t.co/DRfKarLz1d')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary.\n",
        "\n",
        "> üîë **Note:** The previous two concepts (tokenization and embeddings) are the foundation for many NLP tasks. So if you're not sure about anything, be sure to research and conduct your own experiments to further help your understanding."
      ],
      "metadata": {
        "id": "Qb56QccvXlnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling a text dataset\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-inputs-and-outputs-with-shapes-and-models-were-going-to-build.png)\n",
        "*Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.*\n",
        "\n",
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is from Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison\n",
        "\n",
        "Let's get started."
      ],
      "metadata": {
        "id": "AcRT9wMf4E_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        "> Note: It's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them.\n",
        "\n",
        "> üìñ **Reading:** The ins and outs of TF-IDF algorithm is beyond the scope of this notebook, however, the curious reader is encouraged to check out the [Scikit-Learn documentation for more](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)."
      ],
      "metadata": {
        "id": "4dACX6Qq4FGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "                    ])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "VpK15sMV4FMp",
        "outputId": "f29a14c4-ba99-4955-9d43-fa506262ba50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The benefit of using a shallow model like Multinomial Naive Bayes is that training is very fast.\n",
        "\n",
        "Let's evaluate our model and find our baseline metric."
      ],
      "metadata": {
        "id": "gxnwjCw7YPpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5roQ5vO4FTH",
        "outputId": "49f70dd7-9f29-4742-b843-e279e141fd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0piWVTp4FaS",
        "outputId": "b4f0b1f0-1611-4d2b-b176-40decf9cd4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we make some predictions with our baseline model?"
      ],
      "metadata": {
        "id": "gEphqMC9Yvwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MynOAjf64FhU",
        "outputId": "7a5938c2-a6e0-4c33-b896-a422065e8c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIx2J4K44FoP",
        "outputId": "01189b1f-f6cc-47d0-e05d-dea1a0317afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time, however, this will be cumbersome and could easily be fixed with a function.\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "> üîë **Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice.\n",
        "\n",
        "For a deep overview of many different evaluation methods, see the Sklearn documentation: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n"
      ],
      "metadata": {
        "id": "XwHaC3Ns4FvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "tvy5Q6SP27B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NVH0ni-27KD",
        "outputId": "bccfcf7e-87e2-4950-e002-c0b095399cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A simple dense model\n",
        "\n",
        "The first \"deep\" model we're going to build is a single layer dense model. In fact, it's barely going to have a single layer.\n",
        "\n",
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "If the previous sentence sounds like a mouthful, it'll make sense when we code it out (remember, if in doubt, code it out).\n",
        "\n",
        "And since we're going to be building a number of TensorFlow deep learning models, we'll import our `create_tensorboard_callback()` function from `helper_functions.py` to keep track of the results of each."
      ],
      "metadata": {
        "id": "3r8qOq6f27SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "eLCXD0lu27bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a TensorBoard callback function ready to go, let's build our first deep model."
      ],
      "metadata": {
        "id": "Ir5WfPBOZKyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional string\n",
        "x = text_vectorizer(inputs) # turn the inputs text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D(name=\"global_avg_pool_layer\")(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "metadata": {
        "id": "omAq2Rb-27jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good. Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using `text_vectorizer` and creates an embedding using `embedding`.\n",
        "\n",
        "We then (optionally) pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer.\n",
        "\n",
        "> üõ† **Exercise:** Try building `model_1` with and without a `GlobalAveragePooling1D()` layer after the `embedding` layer. What happens? Why do you think this is?\n",
        "\n",
        "Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification).\n",
        "\n",
        "Before we can fit our model to the data, we've got to compile it. Since we're working with binary classification, we'll use `\"binary_crossentropy\"` as our loss function and the Adam optimizer."
      ],
      "metadata": {
        "id": "8_rJMUZVZQ5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QXKoV_Oh270N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi1GDPKZ27ru",
        "outputId": "fa78ae0f-392a-48c2-9459-2c4b39f2daa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_avg_pool_layer (Glo  (None, 128)               0         \n",
            " balAveragePooling1D)                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (`output_dim=128`) for a vocabulary of size 10,000 (`input_dim=10000`), hence the 1,280,000 trainable parameters.\n",
        "\n",
        "Alright, our model is compiled, let's fit it to our training data for 5 epochs. We'll also pass our TensorBoard callback function to make sure our model's training metrics are logged."
      ],
      "metadata": {
        "id": "QCmD980aZWsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1LPYJAw279D",
        "outputId": "12931d47-7683-445b-fbbe-7d2e7708b448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20240102-160732\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 17s 58ms/step - loss: 0.6124 - accuracy: 0.6919 - val_loss: 0.5355 - val_accuracy: 0.7559\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4409 - accuracy: 0.8158 - val_loss: 0.4691 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3466 - accuracy: 0.8629 - val_loss: 0.4541 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2841 - accuracy: 0.8920 - val_loss: 0.4666 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2375 - accuracy: 0.9118 - val_loss: 0.4803 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model is not performing as well as baseline\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDbRHttd28FN",
        "outputId": "99502c55-1ca8-4f96-c596-9cfa9e2c6c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Since we're using such a simple model, each epoch processes very quickly.\n",
        "\n",
        "Let's check our model's performance on the validation set."
      ],
      "metadata": {
        "id": "lIyzj8OAZdmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWAEHz6K28M_",
        "outputId": "38c4b43e-7b6d-4909-dc9f-5560ff5d6331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4803217649459839, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2cFK8-28Vq",
        "outputId": "3d1d9c21-7142-475f-d8c3-765d1100e3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwcw1gWI4F17",
        "outputId": "eba4e47f-79c9-4ce1-89a1-875deaa79746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.42175058], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first 10 prediction\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl9PFPGo4F-v",
        "outputId": "b10276fe-c974-48a0-91aa-01db5fd19599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42175058],\n",
              "       [0.7385078 ],\n",
              "       [0.9981139 ],\n",
              "       [0.11373992],\n",
              "       [0.11218397],\n",
              "       [0.9367492 ],\n",
              "       [0.919198  ],\n",
              "       [0.9940487 ],\n",
              "       [0.97610885],\n",
              "       [0.24948889]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our final layer uses a sigmoid activation function, we get our predictions back in the form of probabilities.\n",
        "\n",
        "To convert them to prediction classes, we'll use `tf.round()`, meaning prediction probabilities below 0.5 will be rounded to 0 and those above 0.5 will be rounded to 1.\n",
        "\n",
        "> üîë **Note:** In practice, the output threshold of a sigmoid prediction probability doesn't necessarily have to 0.5. For example, through testing, you may find that a cut off of 0.25 is better for your chosen evaluation metrics. A common example of this threshold cutoff is the [precision-recall tradeoff](https://en.wikipedia.org/wiki/Precision_and_recall#Introduction) (search for the keyword \"tradeoff\" to learn about the phenomenon)."
      ],
      "metadata": {
        "id": "kZbtlkN7aOTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6TfcevP4GF0",
        "outputId": "6297de43-9b5b-40de-e18b-85479aefbafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got our model's predictions in the form of classes, we can use our `calculate_results()` function to compare them to the ground truth validation labels."
      ],
      "metadata": {
        "id": "6E0pDEXSaQ6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1isp2W54GNf",
        "outputId": "4b72f410-92fe-4b3f-c801-18a196af64bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'precision': 0.7946291128165941,\n",
              " 'recall': 0.7900262467191601,\n",
              " 'f1': 0.7872155322757017}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uLPP0F84GUz",
        "outputId": "17cab42d-c0cb-4f1c-c54c-5e0ba717133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we compare our first deep model to our baseline model?"
      ],
      "metadata": {
        "id": "jxK7tHk_aVUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF5GJuDvq6ni",
        "outputId": "c3386239-25c6-4e6a-ed1e-d8130655e44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing learned embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "Hearing this for the first few times may sound confusing.\n",
        "\n",
        "So to further help understand what a text embedding is, let's visualize the embedding our model learned.\n",
        "\n",
        "To do so, let's remind ourselves of the words in our vocabulary."
      ],
      "metadata": {
        "id": "UXI1fx_Vq6we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyNSIuwLq64_",
        "outputId": "cd56d577-d36c-464b-f25b-c622b14674cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's get our embedding layer's weights (these are the numerical representations of each word)."
      ],
      "metadata": {
        "id": "cEcE6ZJ4aozz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoGZtkR5I_iZ",
        "outputId": "c750a074-4006-4f95-cd7a-fe6a186d7d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_avg_pool_layer (Glo  (None, 128)               0         \n",
            " balAveragePooling1D)                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for ~5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL_kz0G5I_oF",
        "outputId": "19a9be12-3401-4c04-8471-1dbcf1e77b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And since we tracked our model's training logs with TensorBoard, how about we visualize them?\n",
        "\n",
        "We can do so by uploading our TensorBoard log files (contained in the `model_logs` directory) to [TensorBoard.dev](https://tensorboard.dev/).\n",
        "\n",
        "> üîë **Note:** Remember, whatever you upload to TensorBoard.dev becomes public. If there are training logs you don't want to share, don't upload them."
      ],
      "metadata": {
        "id": "tyxJ_W9_Z2op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the embedding matrix and our model has learned to represent our tokens, we can use the [Embedding Projector tool](https://projector.tensorflow.org/) to visualize our embedding.\n",
        "\n",
        "To do so, TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings\n",
        "\n",
        "To use the Embedding Projector tool, we need two files:\n",
        "* The embedding vectors (same as embedding weights).\n",
        "* The meta data of the embedding vectors (the words they represent - our vocabulary).\n",
        "\n",
        "Right now, we've got of these files as Python objects. To download them to file, we're going to [use the code example available on the TensorFlow word embeddings tutorial page](https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk).\n",
        "\n"
      ],
      "metadata": {
        "id": "WlrOwUeXMsPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed_weights"
      ],
      "metadata": {
        "id": "SDmnkv3gI_t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "V-IiwULRI_0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download files from Colab to upload to projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "metadata": {
        "id": "Z-TomH16I_6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the files above we can visualize using https://projector.tensorflow.org/ and clicking the \"load\" button on the left hand side.\n",
        "\n",
        "> **üìïResources:** If you'd like to know more about embeddings, I'd encourage you to check out:\n",
        "* Jay Alammar's visualizd word2vec post: https://jalammar.github.io/illustrated-word2vec/\n",
        "* TensorFlow's Word Embeddings guide: https://www.tensorflow.org/text/guide/word_embeddings\n",
        "\n",
        "Once you've downloaded the embedding vectors and metadata, you can visualize them using Embedding Vector tool:\n",
        "1. Go to  http://projector.tensorflow.org/\n",
        "2. Click on \"Load data\"\n",
        "3. Upload the two files you downloaded (`embedding_vectors.tsv` and `embedding_metadata.tsv`)\n",
        "4. Explore\n",
        "5. Optional: You can share the data you've created by clicking \"Publish\"\n",
        "\n",
        "What do you find?\n",
        "\n",
        "Are words with similar meanings close together?\n",
        "\n",
        "Remember, they might not be. The embeddings we downloaded are how our model interprets words, not necessarily how we interpret them.\n",
        "\n",
        "Also, since the embedding has been learned purely from Tweets, it may contain some strange values as Tweets are a very unique style of natural language.\n",
        "\n",
        "> ü§î **Question:** Do you have to visualize embeddings every time?\n",
        "\n",
        "No. Although helpful for gaining an intuition of what natural language embeddings are, it's not completely necessary. Especially as the dimensions of your vocabulary and embeddings grow, trying to comprehend them would become an increasingly difficult task."
      ],
      "metadata": {
        "id": "dpsw2Z31JAAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input. We use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n",
        "___\n",
        "\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog.\n",
        "\n",
        "See what happened there?\n",
        "\n",
        "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
        "\n",
        "For a simple example, take two sentences:\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "* Long short-term memory cells (LSTMs).\n",
        "* Gated recurrent units (GRUs).\n",
        "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences.\n",
        "\n",
        "___\n",
        "> üìñ **Resources:**\n",
        "> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://www.youtube.com/watch?v=ySEx_Bqxvvo) - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n"
      ],
      "metadata": {
        "id": "HbKPYDX9q7CH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "With all this talk of what RNN's are and what they're good for, I'm sure you're eager to build one.\n",
        "\n",
        "We're going to start with an LSTM-powered RNN.\n",
        "\n",
        "To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-RNN-architecture-coloured-block-edition.png)\n",
        "*Coloured block example of the structure of an recurrent neural network.*\n",
        "\n",
        "Our model is going to take on a very similar structure to `model_1`:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
        "\n",
        "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (`model_2_embedding`) for our model. The `text_vectorizer` layer can be reused since it doesn't get updated during training.\n",
        "\n",
        "> üîë **Note:** The reason we use a new embedding layer for each model is since the embedding layer is a *learned* representation of words (as numbers), if we were to use the same embedding layer (`embedding_1`) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
      ],
      "metadata": {
        "id": "GaZuehkjq7Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LSTM\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to set return_sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "ksOOpJRBxmaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë **Note:** Reading the documentation for the [TensorFlow LSTM layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM), you'll find a plethora of parameters. Many of these have been tuned to make sure they compute as fast as possible. The main ones you'll be looking to adjust are `units` (number of hidden units) and `return_sequences` (set this to `True` when stacking LSTM or other recurrent layers).\n",
        "\n",
        "Now we've got our LSTM model built, let's compile it using `\"binary_crossentropy\"` loss and the Adam optimizer."
      ],
      "metadata": {
        "id": "llJk47WpfCex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dhqzFC_MJLC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And before we fit our model to the data, let's get a summary."
      ],
      "metadata": {
        "id": "XbLvFjPofJsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "Xh16C9BPHXdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa8da46-68ab-4bd8-fe5a-fd66a9cfbc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1329473 (5.07 MB)\n",
            "Trainable params: 1329473 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good! You'll notice a fair few more trainable parameters within our LSTM layer than `model_1`.\n",
        "\n",
        "If you'd like to know where this number comes from, I recommend going through the above resources as well the following on calculating the number of parameters in an LSTM cell:\n",
        "* [Stack Overflow answer to calculate the number of parameters in an LSTM cell](https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network) by Marcin Mo≈ºejko\n",
        "* [Calculating number of parameters in a LSTM unit and layer](https://medium.com/@priyadarshi.cse/calculating-number-of-parameters-in-a-lstm-unit-layer-7e491978e1e4) by Shridhar Priyadarshi\n",
        "\n",
        "Now our first RNN model's compiled let's fit it to our training data, validating it on the validation data and tracking its training parameters using our TensorBoard callback."
      ],
      "metadata": {
        "id": "asJN22uMfM-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xakVBComJLI7",
        "outputId": "abbbae65-fc22-46fd-87a7-fb602995c643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20240102-160803\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 21s 73ms/step - loss: 0.2289 - accuracy: 0.9177 - val_loss: 0.5208 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1598 - accuracy: 0.9412 - val_loss: 0.6817 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1282 - accuracy: 0.9520 - val_loss: 0.6523 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1093 - accuracy: 0.9590 - val_loss: 0.7550 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0895 - accuracy: 0.9675 - val_loss: 0.8615 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We've got our first trained RNN model using LSTM cells. Let's make some predictions with it.\n",
        "\n",
        "The same thing will happen as before, due to the sigmoid activiation function in the final layer, when we call the `predict()` method on our model, it'll return prediction probabilities rather than classes."
      ],
      "metadata": {
        "id": "cVPfPlWqfTuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPqzhXPGJLRD",
        "outputId": "623ba3b4-c8f1-4c9b-f0db-eb9c2625f901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.8020935e-02],\n",
              "       [8.5106039e-01],\n",
              "       [9.9976057e-01],\n",
              "       [7.0618674e-02],\n",
              "       [5.2103848e-04],\n",
              "       [9.9560791e-01],\n",
              "       [6.9974619e-01],\n",
              "       [9.9983060e-01],\n",
              "       [9.9967515e-01],\n",
              "       [5.0173044e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."
      ],
      "metadata": {
        "id": "Vypumq73fXKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ozH852pJLYQ",
        "outputId": "47bf34ca-c3f5-4181-a430-c861e2f4a55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful, now let's use our `calculate_results()` function to evaluate our LSTM model and our `compare_baseline_to_new_results()` function to compare it to our baseline model."
      ],
      "metadata": {
        "id": "M_ZIQmNlfbE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96l0dhg4JLfs",
        "outputId": "05c7854e-9595-4148-b3f0-2f2369eaeaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'precision': 0.7780461459912817,\n",
              " 'recall': 0.7755905511811023,\n",
              " 'f1': 0.7732287214395843}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjr_xSgzJLoj",
        "outputId": "8ee0fdcc-32e5-4d44-b0bd-aa6c5e5b9ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "> üìñ **Resource:** A full explanation of the GRU cell is beyond the scope of this noteook but I'd suggest the following resources to learn more:\n",
        "* [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit) Wikipedia page\n",
        "* [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) by Simeon Kostadinov\n",
        "\n",
        "To use the GRU cell in TensorFlow, we can call the [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) class.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "Again, the only difference will be the layer(s) we use between the embedding and the output."
      ],
      "metadata": {
        "id": "ejNUaFEGJLxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(64, return_sequences=True)(x) # if you want to stack recurrent layers on top of each other, you need return_sequences=True\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(42, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(99)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "VsWhQzD5JL5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow makes it easy to use powerful components such as the GRU cell in our models. And now our third model is built, let's compile it, just as before."
      ],
      "metadata": {
        "id": "I7vTyrV_f2pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "AkCAxUcnJMKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does a summary of our model look like?"
      ],
      "metadata": {
        "id": "gNp0X6zsf6mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsfn9TbwJMCP",
        "outputId": "b139216b-33f7-473b-cadc-704efe7aa59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1317313 (5.03 MB)\n",
            "Trainable params: 1317313 (5.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.\n",
        "\n",
        "We'll fit our model just as we've been doing previously. We'll also track our models results using our `create_tensorboard_callback()` function."
      ],
      "metadata": {
        "id": "GiUg_wapf9AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_3_GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_36wD4-JMTA",
        "outputId": "53a1cbdf-d795-4c48-a43d-32cf119a1c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20240102-160834\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 36ms/step - loss: 0.1527 - accuracy: 0.9431 - val_loss: 0.7143 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0859 - accuracy: 0.9683 - val_loss: 0.7369 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0768 - accuracy: 0.9702 - val_loss: 0.8086 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0636 - accuracy: 0.9753 - val_loss: 1.0743 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9771 - val_loss: 1.1580 - val_accuracy: 0.7808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the optimized default settings of the GRU cell in TensorFlow, training doesn't take long at all.\n",
        "\n",
        "Time to make some predictions on the validation samples."
      ],
      "metadata": {
        "id": "hOWCVS9zgBDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWg9oKZhJMaV",
        "outputId": "c141e97a-6f98-4785-ff8f-54941b4363d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1367997e-03],\n",
              "       [7.5611806e-01],\n",
              "       [9.9966562e-01],\n",
              "       [4.5929503e-02],\n",
              "       [5.2118103e-05],\n",
              "       [9.9952984e-01],\n",
              "       [6.6606659e-01],\n",
              "       [9.9990416e-01],\n",
              "       [9.9980134e-01],\n",
              "       [7.0367646e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."
      ],
      "metadata": {
        "id": "f9x8BICDgEuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwg1f0IjJMh_",
        "outputId": "756f8264-5d53-4825-c0a5-aa844e7f7d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got predicted classes, let's evaluate them against the ground truth labels."
      ],
      "metadata": {
        "id": "bDw5tJwUgHbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "IdcizerVHXkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779c578b-2eb1-4b42-9af2-0eea1a6c0d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'precision': 0.7834583238190046,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1': 0.778533312750939}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "E_Ty6LVhHXrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d0df43-4c56-41ae-88a1-2576501927f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectonal RNN model\n",
        "\n",
        "Look at us go! We've already built two RNN's with GRU and LSTM cells. Now we're going to look into another kind of RNN, the bidirectional RNN.\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "Okay enough talk, let's build a bidirectional RNN.\n",
        "\n",
        "Once again, TensorFlow helps us out by providing the [`tensorflow.keras.layers.Bidirectional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional) class. We can use the `Bidirectional` class to wrap our existing RNNs, instantly making them bidirectional."
      ],
      "metadata": {
        "id": "9qTsZqHXHXyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "# print(x.shape)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "id": "QgfURT7xS-w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell.\n",
        "\n",
        "Our bidirectional model is built, let's compile it."
      ],
      "metadata": {
        "id": "G-1MQvSDi3EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "hSJ2BU_hS-9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And of course, we'll check out a summary."
      ],
      "metadata": {
        "id": "YT4Vo4Vji7G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "69ZInXyVS-4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1737997-ee37-45b9-d87a-b15039a39f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               74496     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1354625 (5.17 MB)\n",
            "Trainable params: 1354625 (5.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "Time to fit our bidirectional model and track its performance."
      ],
      "metadata": {
        "id": "jI9vU4Jxi9dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "id": "9T5I5OrUS_C8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927aa234-8652-413b-d943-12ccaa39bfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20240102-160852\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 38ms/step - loss: 0.1166 - accuracy: 0.9609 - val_loss: 0.9229 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0619 - accuracy: 0.9758 - val_loss: 1.0859 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0521 - accuracy: 0.9781 - val_loss: 1.1414 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.9794 - val_loss: 1.0704 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0437 - accuracy: 0.9800 - val_loss: 1.0181 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the bidirectionality of our model we see a slight increase in training time.\n",
        "\n",
        "Not to worry, it's not too dramatic of an increase.\n",
        "\n",
        "Let's make some predictions with it."
      ],
      "metadata": {
        "id": "cI6xKe4VjBeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "id": "uTiIAKbVS_Ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebe5eed-477e-4250-a09d-414b3991defa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.77632433e-02],\n",
              "       [7.38077164e-01],\n",
              "       [9.99540329e-01],\n",
              "       [2.70226210e-01],\n",
              "       [1.02558195e-04],\n",
              "       [9.99642134e-01],\n",
              "       [6.84844732e-01],\n",
              "       [9.99982834e-01],\n",
              "       [9.99867082e-01],\n",
              "       [9.40862715e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we'll convert them to prediction classes and evaluate them against the ground truth labels and baseline model."
      ],
      "metadata": {
        "id": "3bRNiUaPjFGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "id": "zcHootnfS_MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d013172-dd6d-4ccd-c205-1c2e4c2176eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "mmMViQJzS_Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d60d203-66fd-44d3-c769-61820524db0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7663548384223465,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1': 0.7653289711694428}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results"
      ],
      "metadata": {
        "id": "1hqUCwaGS_Vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b8372c-7032-4082-e32e-83d504f5e155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'precision': 0.7834583238190046,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1': 0.778533312750939}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "Previously we've Conv2D for our image data but now we're going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "You might be thinking \"that just looks like the architecture layout we've been using for the other models...\"\n",
        "\n",
        "And you'd be right.\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) layer followed by a [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) layer.\n",
        "\n",
        "> üìñ **Resource:** The intuition here is explained succinctly in the paper [*Understanding Convolutional Neural Networks for Text Classification*](https://www.aclweb.org/anthology/W18-5408.pdf), where they state that CNNs classify text through the following steps:\n",
        "1. 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "2. Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "3. The rest of the network classifies the text based on this information.\n"
      ],
      "metadata": {
        "id": "J05G6gJHS_aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "> For different explanations of parameters see:\n",
        "* https://poloclub.github.io/cnn-explainer/ (this is for 2D but can relate to 1D data)\n",
        "* Difference between \"same\" and \"valid\" padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
        "\n",
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a **temporal convolution**) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer."
      ],
      "metadata": {
        "id": "wJmKltNmS_fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # this is also referred to an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"same\") # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same shape as input\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "id": "lOXVImG0S_j1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39778d2-271c-4004-c5a0-4de5e7ed396e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the output shapes of each layer.\n",
        "\n",
        "The embedding has an output shape dimension of the parameters we set it to (`input_length=15` and `output_dim=128`).\n",
        "\n",
        "The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool).\n",
        "\n",
        "Let's take a peak at what each of these transformations looks like."
      ],
      "metadata": {
        "id": "O99JIzCEmC4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_test"
      ],
      "metadata": {
        "id": "0Ja1PIbQS_or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv_1d_output"
      ],
      "metadata": {
        "id": "3jASpdQUp2z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_pool_output"
      ],
      "metadata": {
        "id": "aS3UO3Lrp25-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, we've seen the outputs of several components of a CNN for sequences, let's put them together and construct a full model, compile it (just as we've done with our other models) and get a summary."
      ],
      "metadata": {
        "id": "n5wKSD9_mJBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  strides=1,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"same\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# get a summary of our Conv1D mode\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxEgT1J7p2_k",
        "outputId": "9264b527-e404-414e-8b4f-395df1a5cce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 15, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1321089 (5.04 MB)\n",
            "Trainable params: 1321089 (5.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woohoo! Looking great! Notice how the number of trainable parameters for the 1-dimensional convolutional layer is similar to that of the LSTM layer in `model_2`.\n",
        "\n",
        "Let's fit our 1D CNN model to our text data. In line with previous experiments, we'll save its results using our `create_tensorboard_callback()` function."
      ],
      "metadata": {
        "id": "qjQVIm2LmLRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ozqwh6Hp3Fr",
        "outputId": "d8fbf656-6dcc-4798-ec21-8f8f7e5e8fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20240102-160916\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 39ms/step - loss: 0.1070 - accuracy: 0.9645 - val_loss: 0.8953 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 1.0210 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0564 - accuracy: 0.9769 - val_loss: 1.1052 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0513 - accuracy: 0.9775 - val_loss: 1.1474 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0485 - accuracy: 0.9797 - val_loss: 1.1710 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Thanks to GPU acceleration, our 1D convolutional model trains nice and fast. Let's make some predictions with it and evaluate them just as before."
      ],
      "metadata": {
        "id": "a5dH-U9SmPVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r8jgg4-p3LW",
        "outputId": "b327e4b9-98ed-4f2a-8873-810b73cfa479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.3171743e-01],\n",
              "       [9.3711442e-01],\n",
              "       [9.9997902e-01],\n",
              "       [1.0745836e-01],\n",
              "       [4.5818166e-07],\n",
              "       [9.9968314e-01],\n",
              "       [9.2028153e-01],\n",
              "       [9.9999881e-01],\n",
              "       [9.9999988e-01],\n",
              "       [9.4837916e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3pc-Jo5p3SU",
        "outputId": "75db700c-b6ac-4150-fce7-0381c6664daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjeidBObp3Z6",
        "outputId": "fe5701c0-35a3-40bd-eacc-ecf2baf72f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'precision': 0.7556331774317685,\n",
              " 'recall': 0.7559055118110236,\n",
              " 'f1': 0.7557222691548917}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnR8bsEup3hG",
        "outputId": "dfa49e3b-fb34-4728-83ec-a6658589f8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through **transfer learning**. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) from [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4) (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n",
        "\n",
        "> üîë **Note:** There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case.\n"
      ],
      "metadata": {
        "id": "XqJnKUdnmhxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-USE-tensorflow-hub-encoder-decoder-model.png)\n",
        "*The feature extractor model we're building through the eyes of an **encoder/decoder** model.*\n",
        "\n",
        "> üîë **Note:** An **encoder** is the name for a model which converts raw data such as text into a numerical representation (feature vector), a **decoder** converts the numerical representation to a desired output.\n",
        "\n",
        "As usual, this is best demonstrated with an example.\n",
        "\n",
        "We can load in a TensorFlow Hub module using the [`hub.load()`](https://www.tensorflow.org/hub/api_docs/python/hub/load) method and passing it the target URL of the module we'd like to use, in our case, it's \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n",
        "\n",
        "Let's load the Universal Sentence Encoder model and test it on a couple of sentences.\n",
        "\n",
        "> See how th USE was created here: https://arxiv.org/abs/1803.11175"
      ],
      "metadata": {
        "id": "EFK5Sn3Gp3oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you can the universial sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "id": "vgk3dv4Qv7EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fed7d1-faa2-486c-e6d4-bc817de39c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples[0].shape"
      ],
      "metadata": {
        "id": "V0y68S1wv7KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59772e48-8611-4ac8-ef4b-4355405b4238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors, which make no sense to us but hopefully make sense to our machine learning models.\n",
        "\n",
        "Speaking of models, let's build one with the USE as our embedding layer.\n",
        "\n",
        "We can convert the TensorFlow Hub USE module into a Keras layer using the [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) class.\n",
        "\n",
        "> üîë **Note:** Due to the size of the USE TensorFlow Hub module, it may take a little while to download. Once it's downloaded though, it'll be cached and ready to use. And as with many TensorFlow Hub modules, there is a [\"lite\" version of the USE](https://tfhub.dev/google/universal-sentence-encoder-lite/2) which takes up less space but sacrifices some performance and requires more preprocessing steps. However, depending on your available compute power, the lite version may be better for your application use case."
      ],
      "metadata": {
        "id": "zxD5UpqCnda5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "OoPorlOJv7P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful! Now we've got the USE as a Keras layer, we can use it in a Keras Sequential model."
      ],
      "metadata": {
        "id": "MouglG-HnoiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "id": "qDghZ89Nv7Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fef8bc5-667c-4e47-bcd1-f4ebea6d8c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the [Universal Sentence Encoder paper](https://www.aclweb.org/anthology/D18-2029.pdf) for more).\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance.\n",
        "\n",
        "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our `create_tensorboard_callback()` function."
      ],
      "metadata": {
        "id": "g9VqX2-vnsMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of USE pretained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "id": "E1jB_HmJv7bV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7537f85c-8fcc-42f9-faef-f9ba09dffd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20240102-161006\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 21ms/step - loss: 0.5055 - accuracy: 0.7843 - val_loss: 0.4488 - val_accuracy: 0.8031\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4146 - accuracy: 0.8137 - val_loss: 0.4380 - val_accuracy: 0.8110\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4015 - accuracy: 0.8224 - val_loss: 0.4326 - val_accuracy: 0.8176\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3929 - accuracy: 0.8248 - val_loss: 0.4295 - val_accuracy: 0.8163\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.3852 - accuracy: 0.8295 - val_loss: 0.4254 - val_accuracy: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "USE model trained! Let's make some predictions with it an evaluate them as we've done with our other models."
      ],
      "metadata": {
        "id": "HuUBXq3un3b-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "id": "iia56lZrv7g6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc23c18a-d745-4f65-8c82-24e03ded937a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19286336],\n",
              "       [0.80725473],\n",
              "       [0.99045426],\n",
              "       [0.2126233 ],\n",
              "       [0.7748836 ],\n",
              "       [0.70583254],\n",
              "       [0.98193246],\n",
              "       [0.98396444],\n",
              "       [0.95670396],\n",
              "       [0.11016461]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "id": "6ylSSDm4v7m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e36fea-b0d3-4a67-c04c-59c8d0a0eb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "id": "0LrwUZ0_v7tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ac10c4-9063-4a9d-fbbc-f1e5d3e54e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'precision': 0.8151448882654851,\n",
              " 'recall': 0.8149606299212598,\n",
              " 'f1': 0.8142992707815864}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "yHvuk9ELv70I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d69f70-1d18-428f-eb98-4dfd7ea8466a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract).\n",
        "\n",
        "To put this to the test, let's see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
      ],
      "metadata": {
        "id": "dfUBHJaXv77A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "\n",
        "# # Create subset of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# # train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "PS8dY_Bov8F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming a model trained on 100% of data) trust your gut and go back to find where the error may lie."
      ],
      "metadata": {
        "id": "LgqHOJjiH5RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "# len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "7TLPo0cfE7Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we've selected a random subset of the training samples, the classes should be roughly balanced (as they are in the full training dataset)."
      ],
      "metadata": {
        "id": "tevaEBh2pHXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of each label in the updated training data subset\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks4k4JTzFY2a",
        "outputId": "f8a9ceda-0afc-4c16-e43e-b86fcecfe6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_df_shuffled)"
      ],
      "metadata": {
        "id": "uPYEItXev8Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "metadata": {
        "id": "gyNGguQlS_tL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b51bca7-cf1d-4000-a0db-a1c685067cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "metadata": {
        "id": "bmZNAVB8S_yO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2be774-d7c8-4229-bbfa-64eae77a50f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make sure we're making an appropriate comparison between our model's ability to learn from the full training set and 10% subset, we'll clone our USE model (`model_6`) using the [`tf.keras.models.clone_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model) method.\n",
        "\n",
        "Doing this will create the same architecture but reset the learned weights of the clone target (pretrained weights from the USE will remain but all others will be reset)."
      ],
      "metadata": {
        "id": "gC3CmhmWBDJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build a model the same as model_6\n",
        "# model_7 = tf.keras.models.clone_model(model_6)\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"model_7_USE\")\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "id": "aXPb_qUHS_3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1127e170-bd70-45ad-e9e2-06c9bccbd372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the layout of `model_7` is the same as `model_6`. Now let's train the newly created model on our 10% training data subset."
      ],
      "metadata": {
        "id": "L4VIAA2HpbYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBK5nb95veLh",
        "outputId": "fb2fe7eb-0849-4622-ab5b-e743daa91054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20240102-161026\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 46ms/step - loss: 0.6685 - accuracy: 0.6657 - val_loss: 0.6444 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.5975 - accuracy: 0.8102 - val_loss: 0.5872 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.5212 - accuracy: 0.8131 - val_loss: 0.5325 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4606 - accuracy: 0.8307 - val_loss: 0.5017 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4191 - accuracy: 0.8350 - val_loss: 0.4872 - val_accuracy: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the smaller amount of training data, training happens even quicker than before.\n",
        "\n",
        "Let's evaluate our model's performance after learning on 10% of the training data."
      ],
      "metadata": {
        "id": "EKbP4FXBpgiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkETfJRfveR_",
        "outputId": "1522c058-16fa-499c-cbb8-a7abdb8ecd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19760522],\n",
              "       [0.5911701 ],\n",
              "       [0.90254325],\n",
              "       [0.34814084],\n",
              "       [0.5790882 ],\n",
              "       [0.67125   ],\n",
              "       [0.88043916],\n",
              "       [0.80515754],\n",
              "       [0.8557205 ],\n",
              "       [0.13584362]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BkOIZtnveYB",
        "outputId": "716cf7b2-bf05-4043-d6f3-bc9c56cde923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zYWD3lRveeq",
        "outputId": "5cee42b0-f28b-4df3-dca1-4a02036aabd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.7742755789705,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7710949612836401}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAb5rQX2velo",
        "outputId": "9c0be0dd-dff7-47f5-bbb1-cb4af6b14d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'precision': 0.8151448882654851,\n",
              " 'recall': 0.8149606299212598,\n",
              " 'f1': 0.8142992707815864}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the performance of each of our models\n",
        "\n",
        "Woah. We've come a long way! From training a baseline to several deep models.\n",
        "\n",
        "Now it's time to compare our model's results.\n",
        "\n",
        "But just before we do, it's worthwhile mentioning, this type of practice is a standard deep learning workflow. Training various different models, then comparing them to see which one performed best and continuing to train it if necessary.\n",
        "\n",
        "The important thing to note is that for all of our modelling experiments we used the same training data (except for `model_7` where we used 10% of the training data).\n",
        "\n",
        "To visualize our model's performances, let's create a pandas DataFrame we our results dictionaries and then plot it."
      ],
      "metadata": {
        "id": "geVBO-3ever6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TCwgwV13DqMY",
        "outputId": "65aab912-7393-4553-fccb-133e2cdbc9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  accuracy  precision    recall        f1\n",
              "baseline                         79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   79.002625   0.794629  0.790026  0.787216\n",
              "2_lstm                           77.559055   0.778046  0.775591  0.773229\n",
              "3_gru                            78.083990   0.783458  0.780840  0.778533\n",
              "4_bidirectional                  76.640420   0.766355  0.766404  0.765329\n",
              "5_conv1d                         75.590551   0.755633  0.755906  0.755722\n",
              "6_tf_hub_use_encoder             81.496063   0.815145  0.814961  0.814299\n",
              "7_tf_hub_use_encoder_10_percent  77.296588   0.774276  0.772966  0.771095"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c16e7b55-fd1e-45ee-b782-9f970f0d6287\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>79.002625</td>\n",
              "      <td>0.794629</td>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.787216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.778046</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.773229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>78.083990</td>\n",
              "      <td>0.783458</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.778533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766355</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>75.590551</td>\n",
              "      <td>0.755633</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.755722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>81.496063</td>\n",
              "      <td>0.815145</td>\n",
              "      <td>0.814961</td>\n",
              "      <td>0.814299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>77.296588</td>\n",
              "      <td>0.774276</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c16e7b55-fd1e-45ee-b782-9f970f0d6287')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c16e7b55-fd1e-45ee-b782-9f970f0d6287 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c16e7b55-fd1e-45ee-b782-9f970f0d6287');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-524946fe-ddb6-48b4-9403-c83f11ac98d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-524946fe-ddb6-48b4-9403-c83f11ac98d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-524946fe-ddb6-48b4-9403-c83f11ac98d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e04697be-1ff9-4e5d-be9c-f7e4fb92bd75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_model_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e04697be-1ff9-4e5d-be9c-f7e4fb92bd75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_model_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "# all_model_results"
      ],
      "metadata": {
        "id": "LiQ9G6rPDqR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "MMizCsbRDqZp",
        "outputId": "11201e81-2812-4d0b-c2b7-ef908bd19902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our pretrained USE TensorFlow Hub models have the best performance, even the one with only 10% of the training data seems to outperform the other models. This goes to show the power of transfer learning.\n",
        "\n",
        "How about we drill down and get the F1-score's of each model?"
      ],
      "metadata": {
        "id": "SH8Gk8a_psHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(by=\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "5DeqJP81Dqgb",
        "outputId": "60b85040-2195-4eb3-d26a-4c2aeba38092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAMoCAYAAAAHr5UkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnvUlEQVR4nO3deVhV1eL/8c8BBUQBBxQnFKdUrrMkqWmWOKTXofyWYyql3QbMIs0slSwVr5VRV5OcrjaqOZdmJmpOmIVj5gBOaArOmliowO8Pf53bCTQxztm1zvv1POd5OGvvAx88mXxYa69ty8nJyREAAAAAGMTD6gAAAAAAUNAoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADBOIasD3Irs7GwdP35cfn5+stlsVscBAAAAYJGcnBz99NNPKl++vDw8bjxv87coOsePH1dwcLDVMQAAAAD8RRw9elQVK1a84fG/RdHx8/OTdP2b8ff3tzgNAAAAAKtcvHhRwcHB9o5wI3+LovPrcjV/f3+KDgAAAIA/vKSFzQgAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYJxCVgf4qwh5cZnVEf6Uw+M7Wh0BAAAA+MtgRgcAAACAcSg6AAAAAIxD0QEAAABgnNsqOpMnT1ZISIh8fHwUHh6uLVu23PT8uLg41axZU0WKFFFwcLCee+45/fLLL7cVGAAAAAD+SL6Lzty5cxUdHa2YmBht3bpV9evXV7t27XTy5Mk8z//444/14osvKiYmRnv27NGMGTM0d+5cvfTSS386PAAAAADkJd9FZ+LEiRo4cKAiIyMVGhqq+Ph4+fr6aubMmXmev2nTJjVv3ly9evVSSEiI2rZtq549e/7hLBAAAAAA3K58FZ0rV64oKSlJERER//sEHh6KiIhQYmJinq9p1qyZkpKS7MXm4MGDWr58uTp06PAnYgMAAADAjeXrPjqnT59WVlaWgoKCHMaDgoK0d+/ePF/Tq1cvnT59WnfffbdycnJ07do1PfHEEzddupaZmanMzEz784sXL+YnJgAAAAA35/Rd19auXatx48bp3Xff1datW7Vw4UItW7ZMr7322g1fExsbq4CAAPsjODjY2TEBAAAAGCRfMzqBgYHy9PRUenq6w3h6errKli2b52tGjhypRx55RAMGDJAk1a1bVxkZGXr88cf18ssvy8Mjd9caPny4oqOj7c8vXrxI2QEAAABwy/I1o+Pl5aXGjRsrISHBPpadna2EhAQ1bdo0z9dcvnw5V5nx9PSUJOXk5OT5Gm9vb/n7+zs8AAAAAOBW5WtGR5Kio6PVr18/hYWFqUmTJoqLi1NGRoYiIyMlSX379lWFChUUGxsrSerUqZMmTpyohg0bKjw8XCkpKRo5cqQ6depkLzwAAAAAUJDyXXS6d++uU6dOadSoUUpLS1ODBg20YsUK+wYFqampDjM4I0aMkM1m04gRI/Tjjz+qdOnS6tSpk8aOHVtw3wUAAAAA/IYt50brx/5CLl68qICAAF24cMFpy9hCXlzmlM/rKofHd7Q6AgAAAOB0t9oNnL7rGgAAAAC4GkUHAAAAgHHyfY0O4CwsH7Qe7wEAADAFMzoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHzQgA4C+EDSEAACgYzOgAAAAAMA5FBwAAAIBxWLoGAMD/93dfOiixfBAAfsWMDgAAAADjMKMDAAD+MphVA1BQmNEBAAAAYByKDgAAAADjsHQNAAAAdiwfhCmY0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGYdc1AAAA4C+Ene8KBjM6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGua2iM3nyZIWEhMjHx0fh4eHasmXLDc9t1aqVbDZbrkfHjh1vOzQAAAAA3Ey+i87cuXMVHR2tmJgYbd26VfXr11e7du108uTJPM9fuHChTpw4YX98//338vT01EMPPfSnwwMAAABAXvJddCZOnKiBAwcqMjJSoaGhio+Pl6+vr2bOnJnn+SVLllTZsmXtj6+++kq+vr4UHQAAAABOk6+ic+XKFSUlJSkiIuJ/n8DDQxEREUpMTLylzzFjxgz16NFDRYsWzV9SAAAAALhFhfJz8unTp5WVlaWgoCCH8aCgIO3du/cPX79lyxZ9//33mjFjxk3Py8zMVGZmpv35xYsX8xMTAAAAgJtz6a5rM2bMUN26ddWkSZObnhcbG6uAgAD7Izg42EUJAQAAAJggX0UnMDBQnp6eSk9PdxhPT09X2bJlb/rajIwMzZkzR4899tgffp3hw4frwoUL9sfRo0fzExMAAACAm8tX0fHy8lLjxo2VkJBgH8vOzlZCQoKaNm1609d++umnyszMVJ8+ff7w63h7e8vf39/hAQAAAAC3Kl/X6EhSdHS0+vXrp7CwMDVp0kRxcXHKyMhQZGSkJKlv376qUKGCYmNjHV43Y8YMde3aVaVKlSqY5AAAAABwA/kuOt27d9epU6c0atQopaWlqUGDBlqxYoV9g4LU1FR5eDhOFO3bt08bNmzQypUrCyY1AAAAANxEvouOJEVFRSkqKirPY2vXrs01VrNmTeXk5NzOlwIAAACAfHPprmsAAAAA4AoUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxbqvoTJ48WSEhIfLx8VF4eLi2bNly0/PPnz+vp59+WuXKlZO3t7fuuOMOLV++/LYCAwAAAMAfKZTfF8ydO1fR0dGKj49XeHi44uLi1K5dO+3bt09lypTJdf6VK1fUpk0blSlTRvPnz1eFChV05MgRFS9evCDyAwAAAEAu+S46EydO1MCBAxUZGSlJio+P17JlyzRz5ky9+OKLuc6fOXOmzp49q02bNqlw4cKSpJCQkD+XGgAAAABuIl9L165cuaKkpCRFRET87xN4eCgiIkKJiYl5vmbp0qVq2rSpnn76aQUFBalOnToaN26csrKy/lxyAAAAALiBfM3onD59WllZWQoKCnIYDwoK0t69e/N8zcGDB7V69Wr17t1by5cvV0pKip566ildvXpVMTExeb4mMzNTmZmZ9ucXL17MT0wAAAAAbs7pu65lZ2erTJkymjp1qho3bqzu3bvr5ZdfVnx8/A1fExsbq4CAAPsjODjY2TEBAAAAGCRfRScwMFCenp5KT093GE9PT1fZsmXzfE25cuV0xx13yNPT0z5Wu3ZtpaWl6cqVK3m+Zvjw4bpw4YL9cfTo0fzEBAAAAODm8lV0vLy81LhxYyUkJNjHsrOzlZCQoKZNm+b5mubNmyslJUXZ2dn2sf3796tcuXLy8vLK8zXe3t7y9/d3eAAAAADArcr30rXo6GhNmzZNs2fP1p49e/Tkk08qIyPDvgtb3759NXz4cPv5Tz75pM6ePavBgwdr//79WrZsmcaNG6enn3664L4LAAAAAPiNfG8v3b17d506dUqjRo1SWlqaGjRooBUrVtg3KEhNTZWHx//6U3BwsL788ks999xzqlevnipUqKDBgwdr2LBhBfddAAAAAMBv5LvoSFJUVJSioqLyPLZ27dpcY02bNtXmzZtv50sBAAAAQL45fdc1AAAAAHA1ig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOLdVdCZPnqyQkBD5+PgoPDxcW7ZsueG5s2bNks1mc3j4+PjcdmAAAAAA+CP5Ljpz585VdHS0YmJitHXrVtWvX1/t2rXTyZMnb/gaf39/nThxwv44cuTInwoNAAAAADeT76IzceJEDRw4UJGRkQoNDVV8fLx8fX01c+bMG77GZrOpbNmy9kdQUNCfCg0AAAAAN5OvonPlyhUlJSUpIiLif5/Aw0MRERFKTEy84esuXbqkypUrKzg4WF26dNHu3btvPzEAAAAA/IF8FZ3Tp08rKysr14xMUFCQ0tLS8nxNzZo1NXPmTC1ZskQffvihsrOz1axZMx07duyGXyczM1MXL150eAAAAADArXL6rmtNmzZV37591aBBA91zzz1auHChSpcurffee++Gr4mNjVVAQID9ERwc7OyYAAAAAAySr6ITGBgoT09PpaenO4ynp6erbNmyt/Q5ChcurIYNGyolJeWG5wwfPlwXLlywP44ePZqfmAAAAADcXL6KjpeXlxo3bqyEhAT7WHZ2thISEtS0adNb+hxZWVnatWuXypUrd8NzvL295e/v7/AAAAAAgFtVKL8viI6OVr9+/RQWFqYmTZooLi5OGRkZioyMlCT17dtXFSpUUGxsrCTp1Vdf1V133aXq1avr/Pnzev3113XkyBENGDCgYL8TAAAAAPj/8l10unfvrlOnTmnUqFFKS0tTgwYNtGLFCvsGBampqfLw+N9E0blz5zRw4EClpaWpRIkSaty4sTZt2qTQ0NCC+y4AAAAA4DfyXXQkKSoqSlFRUXkeW7t2rcPzt956S2+99dbtfBkAAAAAuC1O33UNAAAAAFyNogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwzm0VncmTJyskJEQ+Pj4KDw/Xli1bbul1c+bMkc1mU9euXW/nywIAAADALcl30Zk7d66io6MVExOjrVu3qn79+mrXrp1Onjx509cdPnxYQ4YMUYsWLW47LAAAAADcinwXnYkTJ2rgwIGKjIxUaGio4uPj5evrq5kzZ97wNVlZWerdu7dGjx6tqlWr/qnAAAAAAPBH8lV0rly5oqSkJEVERPzvE3h4KCIiQomJiTd83auvvqoyZcroscceu/2kAAAAAHCLCuXn5NOnTysrK0tBQUEO40FBQdq7d2+er9mwYYNmzJih7du33/LXyczMVGZmpv35xYsX8xMTAAAAgJtz6q5rP/30kx555BFNmzZNgYGBt/y62NhYBQQE2B/BwcFOTAkAAADANPma0QkMDJSnp6fS09MdxtPT01W2bNlc5x84cECHDx9Wp06d7GPZ2dnXv3ChQtq3b5+qVauW63XDhw9XdHS0/fnFixcpOwAAAABuWb6KjpeXlxo3bqyEhAT7FtHZ2dlKSEhQVFRUrvNr1aqlXbt2OYyNGDFCP/30k95+++0blhdvb295e3vnJxoAAAAA2OWr6EhSdHS0+vXrp7CwMDVp0kRxcXHKyMhQZGSkJKlv376qUKGCYmNj5ePjozp16ji8vnjx4pKUaxwAAAAACkq+i0737t116tQpjRo1SmlpaWrQoIFWrFhh36AgNTVVHh5OvfQHAAAAAG4q30VHkqKiovJcqiZJa9euvelrZ82adTtfEgAAAABuGVMvAAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAY57aKzuTJkxUSEiIfHx+Fh4dry5YtNzx34cKFCgsLU/HixVW0aFE1aNBAH3zwwW0HBgAAAIA/ku+iM3fuXEVHRysmJkZbt25V/fr11a5dO508eTLP80uWLKmXX35ZiYmJ2rlzpyIjIxUZGakvv/zyT4cHAAAAgLzku+hMnDhRAwcOVGRkpEJDQxUfHy9fX1/NnDkzz/NbtWqlBx54QLVr11a1atU0ePBg1atXTxs2bPjT4QEAAAAgL/kqOleuXFFSUpIiIiL+9wk8PBQREaHExMQ/fH1OTo4SEhK0b98+tWzZMv9pAQAAAOAWFMrPyadPn1ZWVpaCgoIcxoOCgrR3794bvu7ChQuqUKGCMjMz5enpqXfffVdt2rS54fmZmZnKzMy0P7948WJ+YgIAAABwc/kqOrfLz89P27dv16VLl5SQkKDo6GhVrVpVrVq1yvP82NhYjR492hXRAAAAABgoX0UnMDBQnp6eSk9PdxhPT09X2bJlb/g6Dw8PVa9eXZLUoEED7dmzR7GxsTcsOsOHD1d0dLT9+cWLFxUcHJyfqAAAAADcWL6u0fHy8lLjxo2VkJBgH8vOzlZCQoKaNm16y58nOzvbYWna73l7e8vf39/hAQAAAAC3Kt9L16Kjo9WvXz+FhYWpSZMmiouLU0ZGhiIjIyVJffv2VYUKFRQbGyvp+jK0sLAwVatWTZmZmVq+fLk++OADTZkypWC/EwAAAAD4//JddLp3765Tp05p1KhRSktLU4MGDbRixQr7BgWpqany8PjfRFFGRoaeeuopHTt2TEWKFFGtWrX04Ycfqnv37gX3XQAAAADAb9zWZgRRUVGKiorK89jatWsdno8ZM0Zjxoy5nS8DAAAAALcl3zcMBQAAAIC/OooOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDi3VXQmT56skJAQ+fj4KDw8XFu2bLnhudOmTVOLFi1UokQJlShRQhERETc9HwAAAAD+rHwXnblz5yo6OloxMTHaunWr6tevr3bt2unkyZN5nr927Vr17NlTa9asUWJiooKDg9W2bVv9+OOPfzo8AAAAAOQl30Vn4sSJGjhwoCIjIxUaGqr4+Hj5+vpq5syZeZ7/0Ucf6amnnlKDBg1Uq1YtTZ8+XdnZ2UpISPjT4QEAAAAgL/kqOleuXFFSUpIiIiL+9wk8PBQREaHExMRb+hyXL1/W1atXVbJkyfwlBQAAAIBbVCg/J58+fVpZWVkKCgpyGA8KCtLevXtv6XMMGzZM5cuXdyhLv5eZmanMzEz784sXL+YnJgAAAAA359Jd18aPH685c+Zo0aJF8vHxueF5sbGxCggIsD+Cg4NdmBIAAADA312+ik5gYKA8PT2Vnp7uMJ6enq6yZcve9LVvvPGGxo8fr5UrV6pevXo3PXf48OG6cOGC/XH06NH8xAQAAADg5vJVdLy8vNS4cWOHjQR+3VigadOmN3zdhAkT9Nprr2nFihUKCwv7w6/j7e0tf39/hwcAAAAA3Kp8XaMjSdHR0erXr5/CwsLUpEkTxcXFKSMjQ5GRkZKkvn37qkKFCoqNjZUk/fvf/9aoUaP08ccfKyQkRGlpaZKkYsWKqVixYgX4rQAAAADAdfkuOt27d9epU6c0atQopaWlqUGDBlqxYoV9g4LU1FR5ePxvomjKlCm6cuWK/u///s/h88TExOiVV175c+kBAAAAIA/5LjqSFBUVpaioqDyPrV271uH54cOHb+dLAAAAAMBtc+muawAAAADgChQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHFuq+hMnjxZISEh8vHxUXh4uLZs2XLDc3fv3q1u3bopJCRENptNcXFxt5sVAAAAAG5JvovO3LlzFR0drZiYGG3dulX169dXu3btdPLkyTzPv3z5sqpWrarx48erbNmyfzowAAAAAPyRfBediRMnauDAgYqMjFRoaKji4+Pl6+urmTNn5nn+nXfeqddff109evSQt7f3nw4MAAAAAH8kX0XnypUrSkpKUkRExP8+gYeHIiIilJiYWODhAAAAAOB2FMrPyadPn1ZWVpaCgoIcxoOCgrR3794CC5WZmanMzEz784sXLxbY5wYAAABgvr/krmuxsbEKCAiwP4KDg62OBAAAAOBvJF9FJzAwUJ6enkpPT3cYT09PL9CNBoYPH64LFy7YH0ePHi2wzw0AAADAfPkqOl5eXmrcuLESEhLsY9nZ2UpISFDTpk0LLJS3t7f8/f0dHgAAAABwq/J1jY4kRUdHq1+/fgoLC1OTJk0UFxenjIwMRUZGSpL69u2rChUqKDY2VtL1DQx++OEH+8c//vijtm/frmLFiql69eoF+K0AAAAAwHX5Ljrdu3fXqVOnNGrUKKWlpalBgwZasWKFfYOC1NRUeXj8b6Lo+PHjatiwof35G2+8oTfeeEP33HOP1q5d++e/AwAAAAD4nXwXHUmKiopSVFRUnsd+X15CQkKUk5NzO18GAAAAAG7LX3LXNQAAAAD4Myg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAAAAjEPRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAAAAAMah6AAAAAAwDkUHAAAAgHEoOgAAAACMQ9EBAAAAYByKDgAAAADjUHQAAAAAGIeiAwAAAMA4FB0AAAAAxqHoAAAAADAORQcAAACAcSg6AAAAAIxD0QEAAABgHIoOAAAAAOPcVtGZPHmyQkJC5OPjo/DwcG3ZsuWm53/66aeqVauWfHx8VLduXS1fvvy2wgIAAADArch30Zk7d66io6MVExOjrVu3qn79+mrXrp1OnjyZ5/mbNm1Sz5499dhjj2nbtm3q2rWrunbtqu+///5PhwcAAACAvOS76EycOFEDBw5UZGSkQkNDFR8fL19fX82cOTPP899++221b99eQ4cOVe3atfXaa6+pUaNGmjRp0p8ODwAAAAB5yVfRuXLlipKSkhQREfG/T+DhoYiICCUmJub5msTERIfzJaldu3Y3PB8AAAAA/qxC+Tn59OnTysrKUlBQkMN4UFCQ9u7dm+dr0tLS8jw/LS3thl8nMzNTmZmZ9ucXLlyQJF28eDE/cfMlO/Oy0z63Kzjzz8ZVeA+sx3tgPd4Da/3d//wl3oO/At4D6/EeWM+Z78GvnzsnJ+em5+Wr6LhKbGysRo8enWs8ODjYgjR/DwFxVicA74H1eA+sx3tgPd4D6/EeWI/3wHqueA9++uknBQQE3PB4vopOYGCgPD09lZ6e7jCenp6usmXL5vmasmXL5ut8SRo+fLiio6Ptz7Ozs3X27FmVKlVKNpstP5H/Ei5evKjg4GAdPXpU/v7+VsdxS7wH1uM9sB7vgfV4D6zHe2At/vytZ8J7kJOTo59++knly5e/6Xn5KjpeXl5q3LixEhIS1LVrV0nXS0hCQoKioqLyfE3Tpk2VkJCgZ5991j721VdfqWnTpjf8Ot7e3vL29nYYK168eH6i/iX5+/v/bf+DMgXvgfV4D6zHe2A93gPr8R5Yiz9/6/3d34ObzeT8Kt9L16Kjo9WvXz+FhYWpSZMmiouLU0ZGhiIjIyVJffv2VYUKFRQbGytJGjx4sO655x69+eab6tixo+bMmaPvvvtOU6dOze+XBgAAAIBbku+i0717d506dUqjRo1SWlqaGjRooBUrVtg3HEhNTZWHx/82c2vWrJk+/vhjjRgxQi+99JJq1KihxYsXq06dOgX3XQAAAADAb9zWZgRRUVE3XKq2du3aXGMPPfSQHnroodv5Ukbw9vZWTExMruV4cB3eA+vxHliP98B6vAfW4z2wFn/+1nOn98CW80f7sgEAAADA30y+bhgKAAAAAH8HFB0AAAAAxqHoAAAAADAORQcAAACAcSg6TnD16lU9+uijOnTokNVRAAAAALfErmtOEhAQoO3bt6tKlSpWRwEAWOzbb7/VmjVrdPLkSWVnZzscmzhxokWpAMBst3UfHfyxrl27avHixXruueesjuL2Dhw4oP/+9786cOCA3n77bZUpU0ZffPGFKlWqpH/84x9WxzPetWvXtHbtWh04cEC9evWSn5+fjh8/Ln9/fxUrVszqeIDTjRs3TiNGjFDNmjUVFBQkm81mP/bbj+E8np6eOnHihMqUKeMwfubMGZUpU0ZZWVkWJTPXgw8+eMvnLly40IlJ3NfSpUtv+dzOnTs7MYl1KDpOUqNGDb366qvauHGjGjdurKJFizocf+aZZyxK5l6+/vpr3X///WrevLnWrVunsWPHqkyZMtqxY4dmzJih+fPnWx3RaEeOHFH79u2VmpqqzMxMtWnTRn5+fvr3v/+tzMxMxcfHWx3ReFWqVLnpD9MHDx50YRr39Pbbb2vmzJnq37+/1VHc1o0Wr2RmZsrLy8vFadxDQECA1RHcXteuXR2e22w2h78Lv/23wdSyT9FxkhkzZqh48eJKSkpSUlKSwzGbzUbRcZEXX3xRY8aMUXR0tPz8/Ozj9913nyZNmmRhMvcwePBghYWFaceOHSpVqpR9/IEHHtDAgQMtTOY+nn32WYfnV69e1bZt27RixQoNHTrUmlBuxsPDQ82bN7c6hlt65513JF3/d3f69OkOs8hZWVlat26datWqZVU8o/33v/+1OoLb++0y2VWrVmnYsGEaN26cmjZtKklKTEzUiBEjNG7cOKsiOh3X6MBoxYoV065du1SlShX5+flpx44dqlq1qg4fPqxatWrpl19+sTqi0UqVKqVNmzapZs2auf78Q0NDdfnyZasjuq3Jkyfru+++44cRF5gwYYKOHz+uuLg4q6O4nV+vkz1y5IgqVqwoT09P+zEvLy+FhITo1VdfVXh4uFURAZeoU6eO4uPjdffddzuMr1+/Xo8//rj27NljUTLnYkbHya5cuaJDhw6pWrVqKlSIP25XK168uE6cOJFrU4ht27apQoUKFqVyH9nZ2XlOhx87dsxhhg2ud//992v48OEUHRcYMmSIOnbsqGrVqik0NFSFCxd2OM71Cc7z6+6n9957rxYuXKgSJUpYnMh9zZ8/X/PmzVNqaqquXLnicGzr1q0WpXIfBw4cUPHixXONBwQE6PDhwy7P4ypsL+0kly9f1mOPPSZfX1/94x//UGpqqiRp0KBBGj9+vMXp3EePHj00bNgwpaWlyWazKTs7Wxs3btSQIUPUt29fq+MZr23btg6/xbbZbLp06ZJiYmLUoUMH64JB8+fPV8mSJa2O4RaeeeYZrVmzRnfccYdKlSqlgIAAhwecb82aNZQcC73zzjuKjIxUUFCQtm3bpiZNmqhUqVI6ePCg7r//fqvjuYU777xT0dHRSk9Pt4+lp6dr6NChatKkiYXJnIula04yePBgbdy4UXFxcWrfvr127typqlWrasmSJXrllVe0bds2qyO6hStXrujpp5/WrFmzlJWVpUKFCikrK0u9evXSrFmzHJYxoOAdO3ZM7dq1U05OjpKTkxUWFqbk5GQFBgZq3bp1uXZAQsFr2LChwwWnOTk5SktL06lTp/Tuu+/q8ccftzCde/Dz89OcOXPUsWNHq6O4raysLM2aNUsJCQl5bvG9evVqi5K5h1q1aikmJkY9e/Z0WMY8atQonT17lmtmXSAlJUUPPPCA9u/fr+DgYEnS0aNHVaNGDS1evFjVq1e3OKFzUHScpHLlypo7d67uuusuh7/UKSkpatSokS5evGh1RLdy9OhR7dq1S5cuXVLDhg1Vo0YNqyO5jWvXrmnOnDnauXOnLl26pEaNGql3794qUqSI1dHcwujRox2ee3h4qHTp0mrVqhUXYbtI5cqV9eWXX/LnbaGoqCjNmjVLHTt2VLly5XLtRPjWW29ZlMw9+Pr6as+ePapcubLKlCmjr776SvXr11dycrLuuusunTlzxuqIbiEnJ0dfffWV9u7dK0mqXbu2IiIijN7mnotGnOTUqVN5/rY6IyPD6P+g/qqCg4MVHBysrKws7dq1S+fOnWMZg4sUKlRIffr0sTqGW7p27ZqqVKmidu3aKSgoyOo4buuVV15RTEyM/vvf/8rX19fqOG5pzpw5mjdvHktmLVK2bFmdPXtWlStXVqVKlbR582bVr19fhw4duuHW3yh4NptNbdu2Vdu2ba2O4jIUHScJCwvTsmXLNGjQIEn/26t8+vTp9m394HzPPvus6tatq8cee0xZWVm65557tGnTJvn6+urzzz9Xq1atrI5ovOTk5BveEX7UqFEWpXIPhQoV0hNPPGHsbjp/F++8844OHDigoKAghYSE5NqMgAuxnc/Ly8vYpTl/B/fdd5+WLl2qhg0bKjIyUs8995zmz5+v7777Ll83FkXBS09P13vvvWfsv8csXXOSDRs26P7771efPn00a9Ys/etf/9IPP/ygTZs26euvv1bjxo2tjugWKlasqMWLFyssLEyLFy/WU089pbVr1+qDDz7Q6tWrtXHjRqsjGm3atGl68sknFRgYqLJly+a6Izw/4Dlfq1at9Oyzz+a6cRxc55VXXrnpTH5MTIwL07inN998UwcPHtSkSZNYVWGB7OxsZWdn23efnTNnjjZt2qQaNWroX//6FzdttdCOHTvUqFEjY28YStFxogMHDmj8+PHasWOH/dqEYcOGqW7dulZHcxs+Pj5KSUlRxYoV9fjjj8vX11dxcXE6dOiQ6tevz7VSTla5cmU99dRTGjZsmNVR3Na8efM0fPhwPffcc2rcuLGKFi3qcLxevXoWJQNc54EHHtCaNWtUsmRJ/eMf/2CLb7iNnTt33vT43r171bNnT4oO8HdUuXJlTZs2Ta1bt1aVKlU0ZcoUdezYUbt379bdd9+tc+fOWR3RaP7+/tq+fbuqVq1qdRS35eGR+y4CNptNOTk5stlsxv7j9ldStWpVffvttypVqpTD+Pnz59WoUSMdPHjQomTuIzIy8qbHuZ+U850/f15btmzJcxkzt3twHg8PD/v/83/PHf4t4BqdApSf2QF/f38nJsGvIiMj9fDDD9t32YmIiJAkffPNN+yA5AIPPfSQVq5cqSeeeMLqKG7r1xsmwjqHDx/O84eIzMxMHTt2zIJE7ociY63PPvtMvXv31qVLl+Tv759rGTNFx3lKliypCRMmqHXr1nke3717tzp16uTiVK5D0SlAxYsXv+W1v6Y257+aV155RXXq1NHRo0f10EMPydvbW5Lk6empF1980eJ05qtevbpGjhypzZs3q27durmWizzzzDMWJXMflStXtjqC21q6dKn94y+//NLh5qBZWVlKSEhQlSpVrIjmlq5du6a1a9fqwIED6tWrl/z8/HT8+HH5+/urWLFiVscz2vPPP69HH31U48aNY+dBF2vcuLGOHz9+w38Lzp8/b/TOdyxdK0Bff/21/ePDhw/rxRdfVP/+/e27rCUmJmr27NmKjY1Vv379rIoJuMzNfoiz2Wws2XGB3/6w/Vs2m00+Pj6qXr06P2w7ya/LBvNaNlK4cGGFhITozTff1D//+U8r4rmVI0eOqH379kpNTVVmZqb279+vqlWravDgwcrMzFR8fLzVEY1WtGhR7dq1i2XMFli0aJEyMjJueJuHc+fOaenSpcb+XErRcZLWrVtrwIAB6tmzp8P4xx9/rKlTp2rt2rXWBHNDCQkJN7wb9syZMy1KBbjGjdZn/3Zt9t13363FixdzbyknqVKlir799lsFBgZaHcVtde3aVX5+fpoxY4ZKlSplv4n32rVrNXDgQCUnJ1sd0WgPPvigevTooYcfftjqKHAzua9SRYFITExUWFhYrvGwsDBt2bLFgkTuafTo0Wrbtq0SEhJ0+vRpnTt3zuEBmO6rr77SnXfeqa+++koXLlzQhQsX9NVXXyk8PFyff/651q1bpzNnzmjIkCFWRzXWoUOHcpWc8+fPWxPGTa1fv14jRozItY1xSEiIfvzxR4tSuY+OHTtq6NCheuWVV7RgwQItXbrU4QHn27Bhg9URLMGMjpPUrFlTXbp00YQJExzGX3jhBS1ZskT79u2zKJl7KVeunCZMmKBHHnnE6ihuIzo6Wq+99pqKFi2q6Ojom547ceJEF6VyX3Xq1NHUqVPVrFkzh/GNGzfq8ccf1+7du7Vq1So9+uijSk1NtSil2f79738rJCRE3bt3l3R9k44FCxaoXLlyWr58uerXr29xQvOVKFFCGzduVGhoqPz8/OwzOhs2bFC3bt2Unp5udUSj5bX7469M3vHrr8TLy0sVKlRQz5491adPH4WGhlodySXYjMBJ3nrrLXXr1k1ffPGFwsPDJUlbtmxRcnKyFixYYHE693HlypVcP+DBubZt26arV6/aP74RbtrnGgcOHMhzl0d/f3/7NVI1atTQ6dOnXR3NbcTHx+ujjz6SdH2GbdWqVVqxYoXmzZunoUOHauXKlRYnNF/btm0VFxenqVOnSrr+/59Lly4pJiZGHTp0sDid+X6/bByud/z4cc2ZM0effPKJxo8fr3r16ql3797q2bOnKlasaHU8p2FGx4mOHTumd999V3v37pUk1a5dW0888YSCg4MtTuY+hg0bpmLFimnkyJFWRwEscffdd8vPz0/vv/++SpcuLUk6deqU+vbtq4yMDK1bt06rVq3S008/zUyzkxQpUkT79+9XcHCwBg8erF9++UXvvfee9u/fr/DwcJbRusCxY8fUrl075eTkKDk5WWFhYUpOTlZgYKDWrVunMmXKWB0RcJlDhw7p448/1ieffKK9e/eqZcuWWr16tdWxnIKiA6MNHjxY77//vurVq6d69erl2t6YpVMw3b59+9SlSxcdOnTI/kuWo0ePqmrVqlqyZInuuOMOLV68WD/99BNLPJ2kfPnymj9/vpo1a6aaNWtqzJgxeuihh7Rv3z7deeed+boHG27ftWvXNHfuXO3YsUOXLl1So0aN1Lt3bxUpUsTqaG7h66+/1htvvKE9e/ZIkkJDQzV06FC1aNHC4mTuKSsrS1988YVGjhypnTt3Grt8kKLjROfPn9eMGTPsf6n/8Y9/6NFHH3W4lwKc6957773hMZvNZuxvMKz04IMP3vK5CxcudGIS/Co7O1srV67U/v37JV2/hrBNmzY3XTePghMVFaXPP/9cNWrU0LZt23T48GEVK1ZMc+bM0YQJE7R161arIwJO9eGHHyoyMlIPPvigmjdvLun6dYKLFi3SrFmz1KtXL4sTuo+NGzfqo48+0vz58/XLL7+oS5cu6t27t9q3b291NKeg6DjJd999p3bt2qlIkSJq0qSJJOnbb7/Vzz//rJUrV6pRo0YWJwScIzIy8pbP5W7lfx1169bV8uXLWVrrBFevXtXbb7+to0ePqn///mrYsKGk69dy+vn5acCAARYnNF9sbKyCgoL06KOPOozPnDlTp06d0rBhwyxK5h5q166txx9/XM8995zD+MSJEzVt2jT7L4ThPMOHD9ecOXN0/PhxtWnTRr1791aXLl2Mv4ErRcdJWrRooerVq2vatGkqVOj6ng/Xrl3TgAEDdPDgQa1bt87ihO4lJSVFBw4cUMuWLVWkSBH7/UMAXPfbnagA04SEhOjjjz/OtTnNN998ox49eujQoUMWJXMP3t7e2r17t6pXr+4wnpKSojp16uiXX36xKJn7aN68uXr37q2HH37Yre7pxa5rTvLdd985lBxJKlSokF544YU8768D5zhz5owefvhhrVmzRjabTcnJyapataoee+wxlShRQm+++abVEY137do1rV27VgcOHFCvXr3k5+en48ePy9/fX8WKFbM6HuAU+bk3SOfOnZ2YBJKUlpamcuXK5RovXbq0Tpw4YUEi9xIcHKyEhIRcRWfVqlXMIrvIxo0brY5gCYqOk/j7+ys1NVW1atVyGD969Kj8/PwsSuV+nnvuORUuXFipqamqXbu2fbx79+6Kjo6m6DjZkSNH1L59e6WmpiozM1Nt2rSRn5+f/v3vfyszM1Px8fFWRwScomvXrrd0HvcQcY3g4GBt3LhRVapUcRjfuHGjypcvb1Eq9/H888/rmWee0fbt2+2zahs3btSsWbP09ttvW5zOfSQnJ2vNmjU6efJkri2/R40aZVEq56LoOEn37t312GOP6Y033nD4Sz106FD17NnT4nTuY+XKlfryyy9z7RFfo0YNHTlyxKJU7mPw4MEKCwvTjh07VKpUKfv4Aw88oIEDB1qYDHAu7hvy1zJw4EA9++yzunr1qu677z5JUkJCgl544QU9//zzFqcz35NPPqmyZcvqzTff1Lx58yRdv25n7ty56tKli8Xp3MO0adP05JNPKjAwUGXLlnVYvm+z2Sg6yJ833nhDNptNffv21bVr1yRJhQsX1pNPPqnx48dbnM59ZGRk5Hmh3dmzZ+Xt7W1BIveyfv16bdq0SV5eXg7jISEh+vHHHy1KBfw1sSGE8wwdOlRnzpzRU089pStXrkiSfHx8NGzYMA0fPtzidO7hgQce0AMPPGB1DLc1ZswYjR071u023mBvUSfx8vLS22+/rXPnzmn79u3avn27zp49q7feeosfsF2oRYsWev/99+3PbTabsrOzNWHChJtuPY2CkZ2dneeynGPHjrGEE/idw4cP6+rVq1bHME5WVpbWr1+vF198UadOndLmzZu1Y8cOnT171tjfYgO/d+7cOT300ENWx3A5dl1zkgsXLigrK0slS5Z0GD979qwKFSokf39/i5K5l++//16tW7dWo0aNtHr1anXu3Fm7d+/W2bNntXHjRlWrVs3qiEbr3r27AgICNHXqVPn5+Wnnzp0qXbq0unTpokqVKrG9tJPt2bNHmzdvVtOmTVWrVi3t3btXb7/9tjIzM9WnTx/7Eh5J+vjjj9WlSxcVLVrUwsTujZ3vnMfHx0d79uzJdY0OnKdkyZLav3+/AgMDVaJEiZvudHr27FkXJnNPjz32mO6880498cQTVkdxKZauOUmPHj3UqVMnPfXUUw7j8+bN09KlS7V8+XKLkrmXOnXqaP/+/Zo0aZL8/Px06dIlPfjgg3r66afz3IEHBevNN99Uu3btFBoaql9++UW9evVScnKyAgMD9cknn1gdz2grVqxQly5dVKxYMV2+fFmLFi1S3759Vb9+fWVnZ6tt27ZauXKlvexwwz6YrE6dOjp48CBFx4V+vU/Urx9zSwdrVa9eXSNHjtTmzZtVt25dFS5c2OH4M888Y1Ey52JGx0lKliypjRs3Ouz0JUl79+5V8+bNdebMGYuSAa517do1zZ07Vzt27NClS5fUqFEj9e7dW0WKFLE6mtGaNWum++67T2PGjNGcOXP01FNP6cknn9TYsWMlXb95XFJSklauXGlxUvyKGR3nWbFihYYPH67XXntNjRs3zjVzySoLmO5mJd9ms+ngwYMuTOM6FB0nKVq0qL01/9auXbsUHh6uy5cvW5TMfDt37rzlc+vVq+fEJIB1AgIClJSUpOrVqys7O1ve3t7asmWLGjZsKOn6ss6IiAilpaVZnBS/oug4j4fH/y5J/u3Mwq83j2aLb+fy9PTUiRMnVKZMGYfxM2fOqEyZMvz5w2lYuuYkTZo00dSpU/Wf//zHYTw+Pl6NGze2KJV7aNCggWw2m/0fsF/92ul/O8b/XJ1r9uzZCgwMVMeOHSVJL7zwgqZOnarQ0FB98sknqly5ssUJzfbrf+seHh7y8fFRQECA/Zifn58uXLhgVTTApdasWWN1BLd2o9+pZ2Zm5tqVE86X189DpqLoOMmYMWMUERGhHTt2qHXr1pKu79n/7bffslTEyQ4dOmT/eNu2bRoyZIiGDh2qpk2bSpISExP15ptvasKECVZFdBvjxo3TlClTJF3/c580aZLi4uL0+eef67nnntPChQstTmiukJAQJScn2zfcSExMVKVKlezHU1NTuU7tL+a9995TUFCQ1TGMdM8991gdwS298847kq7/QD19+nQVK1bMfiwrK0vr1q3LdWN1OM/777+v119/XcnJyZKkO+64Q0OHDtUjjzxicTLnYemaE23fvl2vv/66tm/friJFiqhevXoaPny4atSoYXU0t9GkSRO98sor6tChg8P48uXLNXLkSCUlJVmUzD34+vpq7969qlSpkoYNG6YTJ07o/fff1+7du9WqVSudOnXK6ojGio+PV3BwsH027fdeeuklnTx5UtOnT3dxMvfy888/KykpSSVLllRoaKjDsV9++UXz5s1T3759LUrnXtavX6/33ntPBw8e1KeffqoKFSrogw8+UJUqVXT33XdbHc9Iv14XcuTIEVWsWFGenp72Y15eXgoJCdGrr76q8PBwqyK6jYkTJ2rkyJGKiopS8+bNJUkbNmzQ5MmTNWbMGD333HMWJ3SSHMBgPj4+OT/88EOu8R9++CHHx8fHgkTupXTp0jlbt27NycnJyWnQoEHO+++/n5OTk5OTkpKSU7RoUSujAU63b9++nMqVK+fYbLYcDw+PnJYtW+YcP37cfjwtLS3Hw8PDwoTuY/78+TlFihTJGTBgQI63t3fOgQMHcnJycnL+85//5Nx///0WpzNfq1atcs6ePWt1DLcWEhKSM3v27Fzjs2bNygkJCbEgkWtww1Anys7O1v79+7VhwwatW7fO4QHXqF27tmJjY+13wpakK1euKDY2NteOeCh4bdq00YABAzRgwADt37/fPrO2e/duhYSEWBsOcLJhw4apTp06OnnypPbt2yc/Pz81b95cqampVkdzO2PGjFF8fLymTZvmsK1u8+bNtXXrVguTuYc1a9aoRIkSVsdwaydOnFCzZs1yjTdr1kwnTpywIJFrcI2Ok2zevFm9evXSkSNHcl2Exw4vrhMfH69OnTqpYsWK9h3Wdu7cKZvNps8++8zidOabPHmyRowYoaNHj2rBggUqVaqUJCkpKUk9e/a0OB3gXJs2bdKqVasUGBiowMBAffbZZ3rqqafUokULrVmzhpuzutC+ffvUsmXLXOMBAQE6f/686wO5mW7duqlJkyYaNmyYw/iECRP07bff6tNPP7UomfuoXr265s2bp5deeslhfO7cuUZfUsE1Ok7SoEED3XHHHRo9erTKlSuXa2eL3+5+BOfKyMjQRx99pL1790q6PsvTq1cvfsgA4FT+/v765ptvcs0eR0VFacmSJfr444/VqlUrfvHlAlWrVtXUqVMVERHhsI33+++/r/Hjx+uHH36wOqLRSpcurdWrV+d5y42IiAilp6dblMx9LFiwQN27d1dERIT9Gp2NGzcqISFB8+bN0wMPPGBxQudgRsdJkpOTNX/+fFWvXt3qKG6vaNGievzxx296TseOHTV9+nR2oXKSy5cvKzU11WEJocR9jGC2WrVq6bvvvstVdCZNmiRJ6ty5sxWx3NLAgQM1ePBgzZw5UzabTcePH1diYqKGDBmikSNHWh3PeJcuXcpzG+nChQvr4sWLFiRyP926ddM333yjt956S4sXL5Z0/Re/v72/mokoOk4SHh6ulJQUis7fxLp16/Tzzz9bHcM4p06dUv/+/bVixYo8j/ObbJjsgQce0CeffJLn1q2TJk1Sdna24uPjLUjmfl588UVlZ2erdevWunz5slq2bClvb28NGTJEgwYNsjqe8erWrau5c+dq1KhRDuNz5szJtRshnKdx48b68MMPrY7hUixdc5JFixZpxIgRGjp0qOrWretw8aPEb7L/argjuXP07t1bR44cUVxcnFq1aqVFixYpPT1dY8aM0ZtvvnnDrY8BwBmuXLmilJQUXbp0SaGhoQ73dYHzfPbZZ3rwwQfVq1cv3XfffZKu31vwk08+0aeffqquXbtaG9ANLF++XJ6enmrXrp3D+Jdffqns7Gzdf//9FiVzLoqOk3h45N7QzmazKScnh80I/oIoOs5Rrlw5LVmyRE2aNJG/v7++++473XHHHVq6dKkmTJigDRs2WB0RgJs5evSoJCk4ONjiJO5l2bJlGjdunMO9BWNiYriZq4vUq1dP48ePz3VfwRUrVmjYsGHasWOHRcmci6VrTnLo0CGrIwCWy8jIUJkyZSRJJUqU0KlTp3THHXeobt26bOkKwGWuXbum0aNH65133tGlS5ckScWKFdOgQYMUExOTa9UFCl7Hjh2ZxbdQcnJynssEa9WqpZSUFAsSuQZFx0kqV65sdQTAcjVr1tS+ffsUEhKi+vXr67333lNISIji4+PZ+AGAywwaNEgLFy7UhAkT1LRpU0lSYmKiXnnlFZ05c0ZTpkyxOKH5zp8/r/nz5+vgwYMaMmSISpYsqa1btyooKEgVKlSwOp7xAgICdPDgwVz3sEtJSTF6F1qWrjnRBx98oPj4eB06dEiJiYmqXLmy4uLiVKVKFXXp0sXqePgNlq45x4cffqhr166pf//+SkpKUvv27XXmzBl5eXlp9uzZ6t69u9URAbiBgIAAzZkzJ9d1CMuXL1fPnj114cIFi5K5h507dyoiIkIBAQE6fPiw9u3bp6pVq2rEiBFKTU3V+++/b3VE4/3rX/9SYmKiFi1apGrVqkm6XnK6deumO++8U9OnT7c4oXPkvpAEBWLKlCmKjo5Whw4ddP78efs1OcWLF1dcXJy14ZDLSy+9pJIlS1odwzh9+vRR//79JUmNGjXSkSNH9N133+nYsWOUHAAu4+3tnes32ZJUpUqVPLc9RsGKjo5W//79lZycLB8fH/t4hw4dtG7dOguTuY8JEyaoaNGiqlWrlqpUqaIqVaqodu3aKlWqlN544w2r4zkNRcdJ/vOf/2jatGl6+eWX5enpaR8PCwvTrl27LEzmfj744AM1b95c5cuX15EjRyRJcXFxWrJkif2c4cOHq3jx4hYlNNuMGTNUp04d+fj4qESJEurbt699D38AcIWoqCi99tpryszMtI9lZmZq7NixioqKsjCZe/j222/1r3/9K9d4hQoVlJaWZkEi9xMQEKBNmzZp2bJleuqpp/T8888rISFBq1evNvrnH67RcZJDhw7leQMmb29vZWRkWJDIPU2ZMkWjRo3Ss88+q7Fjx+aaWWMJoXONGjVKEydO1KBBgxzWxT/33HNKTU3Vq6++anFCAO5g27ZtSkhIUMWKFVW/fn1J0o4dO3TlyhW1bt1aDz74oP3chQsXWhXTWN7e3nneGHT//v0qXbq0BYnck81mU9u2bdW2bdsbnlO3bl0tX77cmF0JKTpOUqVKFW3fvj3XpgQrVqzIdZdsOM+vM2tdu3bV+PHj7eNhYWEaMmSIhcncw5QpUzRt2jT17NnTPta5c2fVq1dPgwYNougAcInixYurW7duDmOm/CD3d9C5c2e9+uqrmjdvnqTrP3CnpqZq2LBhud4XWOvw4cO6evWq1TEKDEXHSaKjo/X000/rl19+UU5OjrZs2aJPPvlEsbGxxl7w9VfEzJq1rl69qrCwsFzjjRs31rVr1yxIBMAd/fe//72l8zZu3KjMzEx5e3s7OZF7efPNN/V///d/KlOmjH7++Wfdc889SktLU9OmTTV27Fir48FgFB0nGTBggIoUKaIRI0bo8uXL6tWrl8qXL6+3335bPXr0sDqe22BmzVqPPPKIpkyZookTJzqMT506Vb1797YoFQDk7f7779f27dvZgbOABQQE6KuvvtLGjRu1Y8cOXbp0SY0aNVJERITV0WA4io4T9e7dW71799bly5d16dIl+40Tf2vjxo0KCwvjt0dOwsya60VHR9s/ttlsmj59ulauXKm77rpLkvTNN98oNTVVffv2tSoiAOSJO24UvKtXr6pIkSLavn27mjdvrubNm1sdCW6EouMCvr6+8vX1zfMYvz1yLmbWXG/btm0Ozxs3bixJOnDggCQpMDBQgYGB2r17t8uzAQBcq3DhwqpUqZJ9MyDAlbhhqMW4UaXr3GxmDQAA/k12jhkzZmjhwoX64IMPuGfdX5xpfweY0YHbuNnMGgAAcI5JkyYpJSVF5cuXV+XKlVW0aFGH41u3brUomfvJyMjQvHnzlJKSonLlyqlnz54qVaqU/fh7772noKAgCxMWLIoOjNOwYUPZbLZbOpf/uQIAfnWr/3Ygf7p27Wp1BLcVGhqqDRs2qGTJkjp69Khatmypc+fO6Y477tCBAwf02muvafPmzapSpYokqVevXhYnLlgUHRiH/6ECAG4Hq/mdIyYmxuoIbmvv3r322zkMHz5c5cuX1/bt2xUQEKBLly7pgQce0Msvv6yPP/7Y4qTOwTU6FvP392czAgAAnOzChQtKS0uTJJUtW1YBAQEWJwKcz8PDQ2lpaSpTpoyqVaum+Ph4tWnTxn5806ZN6tGjh1JTUy1M6TzM6FiMnuka3333nfbs2SPp+jTurzuBAQDMNn36dE2cOFH79u1zGK9Zs6aef/55PfbYYxYlM1vJkiW1f/9+BQYGqkSJEjddFnj27FkXJnM/v/7Z//LLLypXrpzDsQoVKujUqVNWxHIJio4TXbt2TWvXrtWBAwfUq1cv+fn56fjx4/L391exYsUkST/99JPFKc127Ngx9ezZUxs3blTx4sUlSefPn1ezZs00Z84cVaxY0dqAAACnef311/XKK6/omWeeUbt27ewXWaenp2vlypUaPHiwzp07pyFDhlic1DxvvfWW/Pz8JElxcXHWhnFzrVu3VqFChXTx4kXt27dPderUsR87cuSIw2YEpmHpmpMcOXJE7du3V2pqqjIzM7V//35VrVpVgwcPVmZmpuLj462O6Bbat2+v8+fPa/bs2apZs6Ykad++fYqMjJS/v79WrFhhcUIAgLNUrlxZr7/+uh5++OE8j8+dO1dDhw41dtkOMHr0aIfnd911l9q1a2d/PnToUB07dkyffPKJq6O5BEXHSbp27So/Pz/NmDFDpUqVsu9JvnbtWg0cOFDJyclWR3QLRYoU0aZNm9SwYUOH8aSkJLVo0UKXL1+2KBkAwNmKFCmirVu3qnbt2nke/+GHHxQWFsa/BU5w8eLFWz7X39/fiUngzli65iTr16/Xpk2b5OXl5TAeEhKiH3/80aJU7ic4OFhXr17NNZ6VlaXy5ctbkAgA4Cp33nmnxo8frxkzZqhQIccfebKysvTvf/9bd955p0XpzFa8ePFb3q47KyvLyWngrig6TpKdnZ3nX9xjx47Z16zC+V5//XUNGjRIkydPVlhYmKTrGxMMHjxYb7zxhsXpAADONGnSJLVr105ly5ZVy5YtHa7RWbdunby8vLRy5UqLU5ppzZo19o8PHz6sF198Uf3791fTpk0lSYmJiZo9e7ZiY2Otigg3wNI1J+nevbsCAgI0depU+fn5aefOnSpdurS6dOmiSpUq6b///a/VEd1CiRIldPnyZV27ds3+27xfP/79nZnZ9QUAzPPTTz/pww8/1ObNmx22l27atKl69erFsikXaN26tQYMGKCePXs6jH/88ceaOnWq1q5da00wGI+i4yTHjh1Tu3btlJOTo+TkZIWFhSk5OVmBgYFat26dypQpY3VEtzB79uxbPrdfv35OTAIAgHvy9fXVjh07VKNGDYfx/fv3q0GDBlwjBaeh6DjRtWvXNHfuXO3YsUOXLl1So0aN1Lt3bxUpUsTqaAAAuL2rV6/qxIkTqlSpktVRjFazZk116dJFEyZMcBh/4YUXtGTJklz3OAIKCkUHbuHkyZM6efKksrOzHcbr1atnUSIAgNV27NihRo0acTG8ky1fvlzdunVT9erVFR4eLknasmWLkpOTtWDBAnXo0MHihDCVh9UBTDV79mwtW7bM/vyFF15Q8eLF1axZMx05csTCZO4lKSlJderUUbly5VSvXj01aNDA/vj9ltMAAKDgdejQQfv371enTp109uxZnT17Vp06ddL+/fspOXAqZnScpGbNmpoyZYruu+8+JSYmqnXr1oqLi9Pnn3+uQoUKaeHChVZHdAv169dXtWrVNGzYMAUFBeXa6rJy5coWJQMAOFujRo1uevznn3/W/v37mdEBDEXRcRJfX1/t3btXlSpV0rBhw3TixAm9//772r17t1q1aqVTp05ZHdEt+Pn5adu2bapevbrVUQAALubj46MePXqoSpUqeR4/ceKEpk2bRtFxgp07d6pOnTry8PDQzp07b3ouy8jhLNxHx0mKFSumM2fOqFKlSlq5cqWio6MlXf+f7s8//2xxOvfRunVr7dixg6IDAG6oTp06Cg8P15NPPpnn8e3bt2vatGkuTuUeGjRooLS0NJUpU0YNGjSQzWZTXr9bt9lsFE04DUXHSdq0aaMBAwaoYcOGDmtQd+/erZCQEGvDuZHp06erX79++v7771WnTh0VLlzY4Xjnzp0tSgYAcLbmzZvfdEcvPz8/tWzZ0oWJ3MehQ4dUunRp+8eAFVi65iTnz5/XiBEjdPToUT355JNq3769JCkmJkZeXl56+eWXLU7oHj777DM98sgjunjxYq5j/BYJAADAXBQdGC0kJET//Oc/NXLkSAUFBVkdBwDwF/bUU0/p1VdfVWBgoNVRjLNv3z795z//0Z49eyRJtWvX1qBBg1SzZk2Lk8FkFB0nWbdu3U2PM1XuGn5+ftq+fbuqVatmdRQAwF+cv7+/tm/frqpVq1odxSgLFixQjx49FBYWpqZNm0qSNm/erG+//VZz5sxRt27dLE4IU1F0nMTDI/ctin67tTFLplyjX79+atGihQYMGGB1FADAX5yfn5927NhB0Slg1apVU+/evfXqq686jMfExOjDDz/UgQMHLEoG07EZgZOcO3fO4fnVq1e1bds2jRw5UmPHjrUolfu54447NHz4cG3YsEF169bNtRnBM888Y1EyAADcw4kTJ9S3b99c43369NHrr79uQSK4C4qOkwQEBOQaa9Omjby8vBQdHa2kpCQLUrmf6dOnq1ixYvr666/19ddfOxyz2WwUHQAAnKxVq1Zav359rls9bNiwQS1atLAoFdwBRcfFgoKCbrrVJQoWW1oCAOB6S5cutX/cuXNnDRs2TElJSbrrrrskXb9G59NPP9Xo0aOtigg3wDU6TvL7uwDn5OToxIkTGj9+vK5du6YNGzZYlAwAAOSFa3QKTl7XKueFWz3AmZjRcZIb3QX4rrvu0syZMy1K5R6io6P12muvqWjRooqOjr7puRMnTnRRKgCAFa5du6Zx48bp0UcfVcWKFW96bp8+feTv7++iZGbLzs62OgLAjI6zHDlyxOG5h4eHSpcuLR8fH4sSuY97771XixYtUvHixXXvvffe8DybzabVq1e7MBkAwAp+fn7atWuXQkJCrI6Cm6hbt66WL1+u4OBgq6PAEBQdi/GXGgAA5+rSpYsefPBB9evXz+oouAmWDqKgsXTNYocPH9bVq1etjuE2Ll68qNWrV6tWrVqqVauW1XEAAC5w//3368UXX9SuXbvUuHFjFS1a1OF4586dLUoGwJmY0bEYv71wrocfflgtW7ZUVFSUfv75Z9WvX1+HDx9WTk4Od2MGADdxswvjuRj+r4OfiVDQbm1LDOBvat26dfY9+hctWqScnBydP39e77zzjsaMGWNxOgCAK2RnZ9/wQckBzEXRgdEuXLigkiVLSpJWrFihbt26ydfXVx07dlRycrLF6QAArvbLL79YHQGAi1B0YLTg4GAlJiYqIyNDK1asUNu2bSVJ586dYwc8AHATWVlZeu2111ShQgUVK1ZMBw8elCSNHDlSM2bMsDid++GqCbgKRQdGe/bZZ9W7d29VrFhR5cuXV6tWrSRdX9JWt25da8MBAFxi7NixmjVrliZMmCAvLy/7eJ06dTR9+nQLk7knb29v7dmzJ9f4e++9p6CgIAsSwVRsRmCxjz/+WF26dMm1AwwKTlJSklJTU9WmTRsVK1ZMkrRs2TIVL15czZs3tzgdAMDZqlevrvfee0+tW7d2uOB97969atq0qc6dO2d1RCPd6Kbdb7/9tvr06aNSpUpJ4ubdcB6KjhMlJCTorbfesv/Wonbt2nr22WcVERFhcTL8nr+/v7Zv385OLwBgoCJFimjv3r2qXLmyQ9H54Ycf1KRJE126dMnqiEby8PBQ/fr1Vbx4cYfxr7/+WmFhYSpatCg374ZTsXTNSd599121b99efn5+Gjx4sAYPHix/f3916NBBkydPtjoefoe+DwDmCg0N1fr163ONz58/Xw0bNrQgkXsYN26cLly4oJEjR2rNmjX2h6enp2bNmqU1a9ZQcuBU3DDUScaNG6e33npLUVFR9rFnnnlGzZs317hx4/T0009bmA4AAPcxatQo9evXTz/++KOys7O1cOFC7du3T++//74+//xzq+MZ68UXX1Tr1q3Vp08fderUSbGxsSpcuLDVseBGmNFxkvPnz6t9+/a5xtu2basLFy5YkAgAAPfUpUsXffbZZ1q1apWKFi2qUaNGac+ePfrss8/Upk0bq+MZ7c4771RSUpJOnTqlsLAwff/997LZbFbHgptgRsdJOnfurEWLFmno0KEO40uWLNE///lPi1IBAOCeWrRooa+++srqGG6pWLFimj17tubMmaOIiAhu0gqXoegUoHfeecf+cWhoqMaOHau1a9eqadOmkqTNmzdr48aNev75562KiBvgt0sAADhXjx49dPfddyspKUmVK1e2Og7cALuuFaAqVarc0nk2m81+szL8Nfx2Fx4AwN9fiRIlbvmXWGfPnnVyGgBWYEanAB06dMjqCLhFR48eVUxMjGbOnClJ+uKLL1ShQgWLUwEACkpcXJz94zNnzmjMmDFq166dfZVFYmKivvzyS40cOdKihACcjRkduKUdO3aoUaNGrBMGADfQrVs33XvvvQ47oUrSpEmTtGrVKi1evNiaYACciqLjJI8++uhNj/86kwDnWLp06U2PHzx4UM8//zxFBwDcQLFixbR9+3ZVr17dYTwlJUUNGjTghqGAoVi65iTnzp1zeH716lV9//33On/+vO677z6LUrmPrl27ymaz3fRGoGxAAADuoVSpUlqyZEmuzYCWLFmiUqVKWZQKgLNRdJxk0aJFucays7P15JNPqlq1ahYkci/lypXTu+++qy5duuR5fPv27WrcuLGLUwEArDB69GgNGDBAa9euVXh4uCTpm2++0YoVKzRt2jSL0wFwFm4Y6kIeHh6Kjo7WW2+9ZXUU4zVu3FhJSUk3PP5Hsz0AAHP0799fGzdulL+/vxYuXKiFCxfK399fGzZsUP/+/a2OB8BJmNFxsQMHDujatWtWxzDe0KFDlZGRccPj1atX15o1a1yYCABgpfDwcH300UdWxwDgQmxG4CTR0dEOz3NycnTixAktW7ZM/fr106RJkyxKBgCA+8nKytLixYu1Z88eSdI//vEPde7cWZ6enhYnA+AsFB0nuffeex2ee3h4qHTp0rrvvvv06KOPqlAhJtMAAHCFlJQUdezYUceOHVPNmjUlSfv27VNwcLCWLVvGtbOAoSg6AADAaB06dFBOTo4++ugjlSxZUtL1m4j26dNHHh4eWrZsmcUJATgDRQcAABitaNGi2rx5s+rWreswvmPHDjVv3pz76ACGYtc1J0lPT9cjjzyi8uXLq1ChQvL09HR4AAAA1/D29tZPP/2Ua/zSpUvy8vKyIBEAV+BCESfp37+/UlNTNXLkSJUrV46bUwIAYJF//vOfevzxxzVjxgw1adJE0vX76DzxxBPq3LmzxekAOAtL15zEz89P69evV4MGDayOAgCAWzt//rz69eunzz77TIULF5YkXbt2TZ07d9asWbMUEBBgcUIAzsCMjpMEBwdzQ0oAAP4CihcvriVLliglJcW+vXTt2rVVvXp1i5MBcCZmdJxk5cqVevPNN/Xee+8pJCTE6jgAAACAW6HoFKASJUo4XIuTkZGha9euydfX1z5V/quzZ8+6Oh4AAG6pW7duatKkiYYNG+YwPmHCBH377bf69NNPLUoGwJkoOgVo9uzZt3xuv379nJgEAAD8qnTp0lq9enWu7aV37dqliIgIpaenW5QMgDNxjU4Bup3yMn78eD3xxBMqXrx4wQcCAAA33Ea6cOHCunjxogWJALgC99Gx2Lhx41jGBgCAE9WtW1dz587NNT5nzhyFhoZakAiAKzCjYzFWDgIA4FwjR47Ugw8+qAMHDui+++6TJCUkJOiTTz7h+hzAYBQdAABgtE6dOmnx4sUaN26c5s+fryJFiqhevXpatWqV7rnnHqvjAXASNiOwmJ+fn3bs2KGqVataHQUAAAAwBjM6AADALVy5ckUnT55Udna2w3ilSpUsSgTAmSg6AADAaMnJyXr00Ue1adMmh/GcnBzZbDZlZWVZlAyAM1F0ClB0dLRee+01FS1aVOvWrVOzZs1UqNDN/4hbtGihIkWKuCghAADup3///ipUqJA+//xzlStXzuHm3gDMxTU6Bahw4cI6duyYgoKC5OnpqRMnTqhMmTJWxwIAwK0VLVpUSUlJqlWrltVRALgQMzoFKCQkRO+8847atm2rnJwcJSYmqkSJEnme27JlSxenAwDAPYWGhur06dNWxwDgYszoFKDFixfriSee0MmTJ2Wz2W54jxzWAwMA4DqrV6/WiBEjNG7cONWtW1eFCxd2OO7v729RMgDORNFxgkuXLsnf31/79u274dK1gIAAF6cCAMA9eXh4SFKua3PYjAAwG0vXnKBYsWJas2aNqlSp8oebEQAAAOdas2aN1REAWIAZHSe50WYEZ86cUZkyZfjtEQAAAOBEHlYHMNWN+mNmZqa8vLxcnAYAAPe2fv169enTR82aNdOPP/4oSfrggw+0YcMGi5MBcBbWVRWwd955R9L1dcDTp09XsWLF7MeysrK0bt06trcEAMCFFixYoEceeUS9e/fW1q1blZmZKUm6cOGCxo0bp+XLl1ucEIAzsHStgFWpUkWSdOTIEVWsWFGenp72Y15eXgoJCdGrr76q8PBwqyICAOBWGjZsqOeee059+/aVn5+fduzYoapVq2rbtm26//77lZaWZnVEAE7AjE4BO3TokCTp3nvv1cKFC294Hx0AAOAa+/bty/P+dQEBATp//rzrAwFwCa7RcZI1a9bcUsnx9/fXwYMHXZAIAAD3VLZsWaWkpOQa37Bhg6pWrWpBIgCuQNGxGCsHAQBwroEDB2rw4MH65ptvZLPZdPz4cX300UcaMmSInnzySavjAXASlq4BAACjvfjii8rOzlbr1q11+fJltWzZUt7e3hoyZIgGDRpkdTwATsJmBBb77UWRAADAea5cuaKUlBRdunRJoaGhDjujStKxY8dUvnx5eXiw4AUwATM6AADALXh5eSk0NPSGx0NDQ7V9+3Z++QgYgl9ZWMxms1kdAQAAiOtmAdNQdCzG/1QBAACAgkfRsdgXX3yhChUqWB0DAAAAMApFp4Bt3brVftNQSfrggw/UvHlzBQcH6+6779acOXMczr/77rvl7e3t6pgAAACA0Sg6BSwyMlIHDhyQJE2fPl3/+te/FBYWppdffll33nmnBg4cqJkzZ1qcEgAA/B7XzQJmYde1ApacnKwaNWpIkt599129/fbbGjhwoP34nXfeqbFjx+rRRx+1KiIAAMgD180CZmFGp4D5+vrq9OnTkqQff/xRTZo0cTgeHh7usLQNAAC4RkpKir788kv9/PPPknIXmx9++EGVK1e2IhoAJ6DoFLD7779fU6ZMkSTdc889mj9/vsPxefPmqXr16lZEAwDALZ05c0YRERG644471KFDB504cUKS9Nhjj+n555+3nxccHCxPT0+rYgIoYLYc5mkL1PHjx9W8eXNVqlRJYWFhmjJliho3bqzatWtr37592rx5sxYtWqQOHTpYHRUAALfQt29fnTx5UtOnT1ft2rW1Y8cOVa1aVV9++aWio6O1e/duqyMCcAKu0Slg5cuX17Zt2zR+/Hh99tlnysnJ0ZYtW3T06FE1b95cGzduVFhYmNUxAQBwGytXrtSXX36pihUrOozXqFFDR44csSgVAGej6DhB8eLFNX78eI0fP97qKAAAuL2MjAz5+vrmGj979iy3eAAMxjU6AADAaC1atND7779vf26z2ZSdna0JEybo3nvvtTAZAGfiGh0AAGC077//Xq1bt1ajRo20evVqde7cWbt379bZs2e1ceNGVatWzeqIAJyAogMAAIx34cIFTZo0STt27NClS5fUqFEjPf300ypXrpzV0QA4CUUHAAAAgHG4RgcAABhtxYoV2rBhg/355MmT1aBBA/Xq1Uvnzp2zMBkAZ6LoAAAAow0dOlQXL16UJO3atUvR0dHq0KGDDh06pOjoaIvTAXAWtpcGAABGO3TokEJDQyVJCxYsUKdOnTRu3Dht3bqVG3gDBmNGBwAAGM3Ly0uXL1+WJK1atUpt27aVJJUsWdI+0wPAPMzoAAAAo919992Kjo5W8+bNtWXLFs2dO1eStH//flWsWNHidACchRkdAABgtEmTJqlQoUKaP3++pkyZogoVKkiSvvjiC7Vv397idACche2lAQAAABiHpWsAAMBoqampNz1eqVIlFyUB4ErM6AAAAKN5eHjIZrPd8HhWVpYL0wBwFWZ0AACA0bZt2+bw/OrVq9q2bZsmTpyosWPHWpQKgLMxowMAANzSsmXL9Prrr2vt2rVWRwHgBOy6BgAA3FLNmjX17bffWh0DgJOwdA0AABjt9zcFzcnJ0YkTJ/TKK6+oRo0aFqUC4GwUHQAAYLTixYvn2owgJydHwcHBmjNnjkWpADgb1+gAAACjff311w7PPTw8VLp0aVWvXl2FCvE7X8BUFB0AAABJHTt21PTp01WuXDmrowAoAGxGAAAAIGndunX6+eefrY4BoIBQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBxKDoAAACSXnrpJZUsWdLqGAAKCPfRAQAAxtu3b5/+85//aM+ePZKk2rVra9CgQapZs6bFyQA4CzM6AADAaAsWLFCdOnWUlJSk+vXrq379+tq6davq1KmjBQsWWB0PgJMwowMAAIxWrVo19e7dW6+++qrDeExMjD788EMdOHDAomQAnImiAwAAjObr66udO3eqevXqDuPJycmqX7++Ll++bFEyAM7E0jUAAGC0Vq1aaf369bnGN2zYoBYtWliQCIArFLI6AAAAQEFbunSp/ePOnTtr2LBhSkpK0l133SVJ2rx5sz799FONHj3aqogAnIylawAAwDgeHre2aMVmsykrK8vJaQBYgaIDAAAAwDhcowMAAADAOFyjAwAAjPb7baV/b9SoUS5KAsCVWLoGAACM1rBhQ4fnV69e1aFDh1SoUCFVq1ZNW7dutSgZAGdiRgcAABht27ZtucYuXryo/v3764EHHrAgEQBXYEYHAAC4pV27dqlTp046fPiw1VEAOAGbEQAAALd04cIFXbhwweoYAJyEpWsAAMBo77zzjsPznJwcnThxQh988IHuv/9+i1IBcDaWrgEAAKNVqVLF4bmHh4dKly6t++67T8OHD5efn59FyQA4E0UHAAAAgHG4RgcAAACAcbhGBwAAGC0jI0Pjx49XQkKCTp48qezsbIfjBw8etCgZAGei6AAAAKMNGDBAX3/9tR555BGVK1dONpvN6kgAXIBrdAAAgNGKFy+uZcuWqXnz5lZHAeBCXKMDAACMVqJECZUsWdLqGABcjKIDAACM9tprr2nUqFG6fPmy1VEAuBBL1wAAgHEaNmzocC1OSkqKcnJyFBISosKFCzucu3XrVlfHA+ACbEYAAACM07VrV6sjALAYMzoAAACSPvnkE3Xu3FlFixa1OgqAAkDRAQAAkOTv76/t27eratWqVkcBUADYjAAAAEASv/sFzELRAQAAAGAcig4AAAAA41B0AAAAABiHogMAAADAOBQdAABgnHfeeUe//PKLJCk1NfWWNhqoXLlyrpuJAvj7YntpAABgnEKFCun48eMqU6aMPD09deLECZUpU8bqWABcqJDVAQAAAApa+fLltWDBAnXo0EE5OTk6duyYfYbn9ypVquTidABcgRkdAABgnKlTp2rQoEG6du3aDc/JycmRzWZTVlaWC5MBcBWKDgAAMNJPP/2kI0eOqF69elq1apVKlSqV53n169d3cTIArkDRAQAARps9e7Z69Oghb29vq6MAcCF2XQMAAEYbPXq0Ll26lGv8/Pnzqlq1qgWJALgCRQcAABjt8OHDeV6Hk5mZqR9//NGCRABcgV3XAACAkZYuXWr/+Msvv1RAQID9eVZWlhISEhQSEmJBMgCuwDU6AADASB4e1xeu2Gy2XDcMLVy4sEJCQvTmm2/qn//8pxXxADgZRQcAABitSpUq+vbbbxUYGGh1FAAuxDU6AADAaIcOHbqlklO3bl0dPXrUBYkAuAJFBwAAQNc3Lbh69arVMQAUEIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAGGnQoEFav379LZ//3nvvKSgoyImJALgSNwwFAABG8vDwkM1mU7Vq1fTYY4+pX79+Klu2rNWxALgIMzoAAMBYK1euVIcOHfTGG2+oUqVK6tKliz7//HNlZ2dbHQ2Ak1F0AACAserWrau4uDgdP35cH374oTIzM9W1a1cFBwfr5ZdfVkpKitURATgJS9cAAICRPDw8lJaWpjJlyjiMp6amaubMmZo1a5aOHj2qrKwsixICcCaKDgAAMNKNis6vcnJytGrVKrVp08bFyQC4AkvXAACAkSpXrixPT88bHrfZbJQcwGDM6AAAAAAwDjM6AAAAAIxD0QEAAABgHIoOAAAAAONQdAAAAAAYh6IDAAAAwDgUHQAAAADGoegAAAAAMA5FBwAAAIBx/h+JXnCnk+2P4AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drilling down into a single metric we see our USE TensorFlow Hub models performing  better than all of the other models. Interestingly, the baseline's F1-score isn't too far off the rest of the deeper models.\n"
      ],
      "metadata": {
        "id": "ssxz_Zq6pzvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n",
        "\n",
        "We can further inspect our model's data using TensorBoard.dev: https://tensorboard.dev/"
      ],
      "metadata": {
        "id": "MN8xcrJoDqnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "Although training time didn't take very long, it's good practice to save your trained models to avoid having to retrain them.\n",
        "\n",
        "Saving your models also enables you to export them for use elsewhere outside of your notebooks, such as in a web application.\n",
        "\n",
        "There are two main ways of [saving a model in TensorFlow](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n",
        "1. The `HDF5` format.\n",
        "2. The `SavedModel` format (default).\n",
        "\n",
        "Let's take a look at both."
      ],
      "metadata": {
        "id": "sIhC0PzrDqvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "HQ5KYxGMDq3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6e51b8-9ff9-4acd-f978-3afd1db20b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you save a model as a `HDF5`, when loading it back in, you need to let [TensorFlow know about any custom objects you've used](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects) (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."
      ],
      "metadata": {
        "id": "PDsQGLJwqBOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "metadata": {
        "id": "CLCDAkcWDq_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "t4KnAYepDrJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f462266-8fc1-418f-bf72-a9df7be6a8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4254 - accuracy: 0.8150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4253646433353424, 0.8149606585502625]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the `save()` method on our target model and passing it a filepath allows us to save our model in the `SavedModel` format.\n",
        "\n",
        "Now let's save to the `SavedModel` format... (see more on this here: https://www.tensorflow.org/tutorials/keras/save_and_load)"
      ],
      "metadata": {
        "id": "T6dtWj4GDrSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_savedModel_format\")"
      ],
      "metadata": {
        "id": "U1Z2B3dFveyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use SavedModel format (default), you can reload your model without specifying custom objects using the [`tensorflow.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load) function."
      ],
      "metadata": {
        "id": "N7OBXkjGqMIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a model from the SavedModel format\n",
        "loaded_model_6_savedModel_format = tf.keras.models.load_model(\"model_6_savedModel_format\")"
      ],
      "metadata": {
        "id": "Csa-CVjSve5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model in SavedModel format\n",
        "loaded_model_6_savedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "rBsEERClvfAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a8ee21-4e1f-42a8-bd52-0e30ee36f821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4254 - accuracy: 0.8150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4253646433353424, 0.8149606585502625]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see saving and loading our model with either format results in the same performance.\n",
        "\n",
        "> ü§î **Question:** Should you used the `SavedModel` format or `HDF5` format?\n",
        "\n",
        "For most use cases, the `SavedModel` format will suffice. However, this is a TensorFlow specific standard. If you need a more general-purpose data standard, `HDF5` might be better. For more, check out the [TensorFlow documentation on saving and loading models](https://www.tensorflow.org/tutorials/keras/save_and_load)."
      ],
      "metadata": {
        "id": "k-hSwirEqR78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "We mentioned before that if many of our modelling experiments are returning similar results, despite using different kinds of models, it's a good idea to return to the data and inspect why this might be.\n",
        "\n",
        "One of the best ways to inspect your data is to sort your model's predictions and find the samples it got *most* wrong, meaning, what predictions had a high prediction probability but turned out to be wrong.\n",
        "\n",
        "Once again, visualization is your friend. Visualize, visualize, visualize.\n",
        "\n",
        "To make things visual, let's take our best performing model's prediction probabilities and classes along with the validation samples (text and ground truth labels) and combine them in a pandas DataFrame.\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of these wrong examples which ones it is getting *most* wrong (those with prediction probabilities closest to the opposite class)\n",
        "* Are there some labels which are wrong? E.g. the model gets it right but the ground truth label doesn't reflect this\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
      ],
      "metadata": {
        "id": "PLMqR4sIvfHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained model from Google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw4BehSX_wnZ",
        "outputId": "831ea175-2e88-4c35-b7b8-a78857e1022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-02 16:27:46--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.207, 142.250.99.207, 173.194.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‚Äò08_model_6_USE_feature_extractor.zip‚Äô\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  26.5MB/s    in 16s     \n",
            "\n",
            "2024-01-02 16:28:03 (56.0 MB/s) - ‚Äò08_model_6_USE_feature_extractor.zip‚Äô saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjTBTpR3AUEE",
        "outputId": "06dbfa0e-459c-4e10-d806-32f54f29f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # these should be in label format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2CQL8om-_h1",
        "outputId": "733b23d6-f29b-49ca-b7f2-fc9095f92617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best perforing model predictions labels + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LJnNYUTg-_pZ",
        "outputId": "278e2185-986f-4e54-a99b-08d022934ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-288272b0-fc67-49c3-bf8b-fde97adc4fea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-288272b0-fc67-49c3-bf8b-fde97adc4fea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-288272b0-fc67-49c3-bf8b-fde97adc4fea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-288272b0-fc67-49c3-bf8b-fde97adc4fea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f9f9373-6833-4cad-bf3a-4603115fc38b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f9f9373-6833-4cad-bf3a-4603115fc38b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f9f9373-6833-4cad-bf3a-4603115fc38b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh yeah! Now let's find our model's wrong predictions (where `target != pred`) and sort them by their prediction probability (the `pred_prob` column)."
      ],
      "metadata": {
        "id": "APIPSPHVq6C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(by=\"pred_prob\", ascending=False)\n",
        "most_wrong[:10] # these are false positives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "evaxopIL-_xn",
        "outputId": "e623d530-b87a-4d62-fedf-9e6ef0564f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   \n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "31    0.910196  \n",
              "759   0.876982  \n",
              "628   0.852300  \n",
              "209   0.835454  \n",
              "251   0.827213  \n",
              "393   0.814816  \n",
              "109   0.810840  \n",
              "49    0.803122  \n",
              "119   0.766901  \n",
              "344   0.766625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-743f5fcf-78c4-4603-ba24-b8d9cb6acf1a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-743f5fcf-78c4-4603-ba24-b8d9cb6acf1a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-743f5fcf-78c4-4603-ba24-b8d9cb6acf1a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-743f5fcf-78c4-4603-ba24-b8d9cb6acf1a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c5323f9-6102-4203-a274-72ac33c28a4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c5323f9-6102-4203-a274-72ac33c28a4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c5323f9-6102-4203-a274-72ac33c28a4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong.tail(10) # these are false negatives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "fymozUpICyEM",
        "outputId": "17bbcc63-5fa7-4e5f-e1f4-fcaf2aef99c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "536      @DavidVonderhaar At least you were sincere ??       1   0.0   \n",
              "408  @willienelson We need help! Horses will die!Pl...       1   0.0   \n",
              "294  Lucas Duda is Ghost Rider. Not the Nic Cage ve...       1   0.0   \n",
              "221  going to redo my nails and watch behind the sc...       1   0.0   \n",
              "59   You can never escape me. Bullets don't harm me...       1   0.0   \n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "233                    I get to smoke my shit in peace       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "244  Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "\n",
              "     pred_prob  \n",
              "536   0.067303  \n",
              "408   0.055076  \n",
              "294   0.054603  \n",
              "221   0.054597  \n",
              "59    0.049637  \n",
              "411   0.043918  \n",
              "233   0.042087  \n",
              "38    0.038998  \n",
              "244   0.038949  \n",
              "23    0.037186  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac8bd7a2-74f0-4238-8998-d2eb979e7612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>@DavidVonderhaar At least you were sincere ??</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.067303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>Lucas Duda is Ghost Rider. Not the Nic Cage ve...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>going to redo my nails and watch behind the sc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>You can never escape me. Bullets don't harm me...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac8bd7a2-74f0-4238-8998-d2eb979e7612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac8bd7a2-74f0-4238-8998-d2eb979e7612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac8bd7a2-74f0-4238-8998-d2eb979e7612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02cc17ce-4a9b-4b60-9f2f-85561f2e1b62\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02cc17ce-4a9b-4b60-9f2f-85561f2e1b62')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02cc17ce-4a9b-4b60-9f2f-85561f2e1b62 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can write some code to visualize the sample text, truth label, prediction class and prediction probability. Because we've sorted our samples by prediction probability, viewing samples from the head of our `most_wrong` DataFrame will show us false positives.\n",
        "\n",
        "Let's remind ourselves of the target labels...\n",
        "* `0` = Not a real diaster Tweet\n",
        "* `1` = Real diaster Tweet"
      ],
      "metadata": {
        "id": "1VGwPwp3-_5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "    _, text, target, pred, pred_prob = row\n",
        "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "    print(f\"Text:\\n{text}\\n\")\n",
        "    print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVzkA1Ta_AB9",
        "outputId": "c6e4005d-41a3-47a2-b315-1d5bc900c429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769821524620056\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523001074790955\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544639587402\n",
            "Text:\n",
            "Ashes 2015: Australia¬â√õ¬™s collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132873535156\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.814815878868103\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108396530151367\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8031218647956848\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669007182121277\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7666252255439758\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can view the bottom end of our `most_wrong` DataFrame to inspect false negatives (model predicts 0, not a real diaster Tweet, when it should've predicted 1, real diaster Tweet)."
      ],
      "metadata": {
        "id": "mE34DtDfvUg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false negatives (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "    _, text, target, pred, pred_prob = row\n",
        "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "    print(f\"Text:\\n{text}\\n\")\n",
        "    print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-OuAOtS_AK9",
        "outputId": "d9392465-b1bc-4527-b099-a2978560ffbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05507583171129227\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05460337549448013\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05459701269865036\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.049637261778116226\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.042086850851774216\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.038997944444417953\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03894945606589317\n",
            "Text:\n",
            "Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718579187989235\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you notice anything interesting about the most wrong samples?\n",
        "\n",
        "Are the ground truth labels correct? What do you think would happen if we went back and corrected the labels which aren't?"
      ],
      "metadata": {
        "id": "pgc7MZuWvZNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset\n",
        "\n",
        "Alright we've seen how our model's perform on the validation set.\n",
        "\n",
        "But how about the test dataset?\n",
        "\n",
        "We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves.\n",
        "\n",
        "Let's write some code to make predictions on random samples from the test dataset and visualize them."
      ],
      "metadata": {
        "id": "auKLt4r-_AUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxSAOn32_Acq",
        "outputId": "e5180bed-0798-48ba-c7b5-8bd93cb134ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 163ms/step\n",
            "Pred: 0, Prob: 0.31043872237205505\n",
            "Text:\n",
            "Not only did Drake kill Meek Mill but he started T bagging his his dead body ????????????\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Pred: 0, Prob: 0.191587433218956\n",
            "Text:\n",
            "@funnychubbyguy poor white guy his mom made him pizza and he wanted mac n cheese so he blew up a school. Such a sad story.\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Pred: 1, Prob: 0.8519179821014404\n",
            "Text:\n",
            "NetNewsLedger Wild Fire Update ¬â√õ√í August 4 2015: THUNDER BAY ¬â√õ√í WEATHER ¬â√õ√í There√•√äwere no new fires confirmed by t... http://t.co/JflxgEmBdA\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Pred: 1, Prob: 0.5752082467079163\n",
            "Text:\n",
            "#Np love police @PhilCollinsFeed On #LateNiteMix Uganda Broadcasting Corporation. UBC 98FM #Radio/ #Uganda / #MbbLive\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Pred: 0, Prob: 0.07586993277072906\n",
            "Text:\n",
            "I added a video to a @YouTube playlist http://t.co/c2k7hDoLph Howie Day - Collide\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Pred: 1, Prob: 0.9843393564224243\n",
            "Text:\n",
            "Officer Wounded Suspect Killed in Exchange of Gunfire http://t.co/HHSjnAVHUA\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Pred: 1, Prob: 0.8031371235847473\n",
            "Text:\n",
            "Arsonist Sets NYC Vegetarian Restaurant on Fire: Police #NewYork - http://t.co/agn4cL4uSK\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Pred: 0, Prob: 0.0943201556801796\n",
            "Text:\n",
            "RT @judithabarrow author CHANGING PATTERNS  #amazon http://t.co/0oCrOtMkHM SILENT TRAUMA http://t.co/2ZGrVnMDW9 #amazon\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Pred: 0, Prob: 0.16888505220413208\n",
            "Text:\n",
            "@Pandamoanimum Duly noted.The involuntary wince I have when people send me words like 'holibobs' must make it look like I have trapped wind.\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Pred: 0, Prob: 0.40659138560295105\n",
            "Text:\n",
            "#NowPlaying  - Lamb of God - Desolation http://t.co/mUYWttEdl6\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do our model's predictions look on the test dataset?\n",
        "\n",
        "It's important to do these kind of visualization checks as often as possible to get a glance of how your model performs on unseen data and subsequently how it might perform on the real test: Tweets from the wild."
      ],
      "metadata": {
        "id": "NYIQUBflviT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your challenge... predicting on Tweets from the wild\n",
        "\n",
        "Go to your favourite Twitter account and copy one of their latest Tweets.\n",
        "\n",
        "Then pass that Tweet through our trained model.\n",
        "\n",
        "Is that Tweet a disaster or not disaster (according to the model)? Is the model right or not wrong?"
      ],
      "metadata": {
        "id": "3PPCxySyFAFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff\n",
        "\n",
        "One of the final tests we're going to do is to find the speed/score tradeoffs between our best model and baseline model.\n",
        "\n",
        "Why is this important?\n",
        "\n",
        "Although it can be tempting to just choose the best performing model you find through experimentation, this model might not actually work in a production setting.\n",
        "\n",
        "Put it this way, imagine you're Twitter and receive 1 million Tweets per hour (this is a made up number, the actual number is much higher). And you're trying to build a diaster detection system to read Tweets and alert authorities with details about a diaster in close to real-time.\n",
        "\n",
        "Compute power isn't free so you're limited to a single compute machine for the project. On that machine, one of your models makes 10,000 predictions per second at 80% accuracy where as another one of your models (a larger model) makes 100 predictions per second at 85% accuracy.\n",
        "\n",
        "Which model do you choose?\n",
        "\n",
        "Is the second model's performance boost worth missing out on the extra capacity?\n",
        "\n",
        "Of course, there are many options you could try here, such as sending as many Tweets as possible to the first model and then sending the ones which the model is least certain of to the second model.\n",
        "\n",
        "The point here is to illustrate the best model you find through experimentation, might not be the model you end up using in production.\n",
        "\n",
        "To make this more concrete, let's write a function to take a model and a number of samples and time how long the given model takes to make predictions on those samples."
      ],
      "metadata": {
        "id": "T3z9kiWyFAMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "\n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time - start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "hiFm5VlNFAVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good!\n",
        "\n",
        "Now let's use our `pred_timer()` function to evaluate the prediction times of our best performing model (`model_6`) and our baseline model (`model_0`)."
      ],
      "metadata": {
        "id": "Zp2tFO9Fv0Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5DQcgylFAde",
        "outputId": "ef37ab7d-5dad-453c-a6c3-99ca8806d168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5038006920003681, 0.0006611557637800107)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z3Rx9qpFAmN",
        "outputId": "479cfd90-3418-4ac5-8f0c-a3e4768665db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.022563820000414125, 2.9611312336501475e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get results for pretrained GS model\n",
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s9uEhsuILyV",
        "outputId": "db2443ca-b915-4440-fb42-a31ae1ade64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8148082644367335}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems with our current hardware (in my case, I'm using a Google Colab notebook) our best performing model takes over 10x the time to make predictions as our baseline model.\n",
        "\n",
        "Is that extra prediction time worth it?\n",
        "\n",
        "Let's compare time per prediction versus our model's F1-scores."
      ],
      "metadata": {
        "id": "34qpIJvOv5A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "DGxOPGdQ_Al9",
        "outputId": "74b05324-9663-4551-c6da-4ced1350e9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-ideal-performance-speed-of-pred-tradeoff-highlighted.png)\n",
        "*Ideal position for speed and performance tradeoff model (fast predictions with great results).*\n",
        "\n",
        "Of course, the ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score).\n",
        "\n",
        "In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n",
        "\n",
        "This kind of tradeoff is something you'll need to keep in mind when incorporating machine learning models into your own applications."
      ],
      "metadata": {
        "id": "5su9IHrbv9IN"
      }
    }
  ]
}